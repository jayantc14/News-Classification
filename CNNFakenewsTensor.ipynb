{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNFakenewsTensor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SSu7Vcjfc9YI_sFXEasqD9P7RH1MdTIZ",
      "authorship_tag": "ABX9TyMkq4qLPRKjWKFrca8hflD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayantc14/News-Classification/blob/main/CNNFakenewsTensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5YqMRj-p5tl"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "import gc # for deleting unused variables\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru8ano75i-R_",
        "outputId": "32cdef91-9521-41d9-a273-c0172a0b6b46"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMtAnEiiq97H"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/IIM/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yvkB4QZron2"
      },
      "source": [
        "df.drop(['Unnamed: 0'],axis = 1,inplace  = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QWxCRfSfrpzu",
        "outputId": "0358a21b-c296-40c9-9877-980e747fd2a2"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>Sixltr</th>\n",
              "      <th>number</th>\n",
              "      <th>quant</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>tentat</th>\n",
              "      <th>certain</th>\n",
              "      <th>achieve</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focuspast</th>\n",
              "      <th>focuspresent</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>FREScore</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97.02</td>\n",
              "      <td>22.27</td>\n",
              "      <td>35.07</td>\n",
              "      <td>23.41</td>\n",
              "      <td>28.44</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1.34</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.20</td>\n",
              "      <td>5.87</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.93</td>\n",
              "      <td>4.01</td>\n",
              "      <td>6.81</td>\n",
              "      <td>2.00</td>\n",
              "      <td>42.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96.86</td>\n",
              "      <td>13.98</td>\n",
              "      <td>49.52</td>\n",
              "      <td>20.23</td>\n",
              "      <td>32.85</td>\n",
              "      <td>2.39</td>\n",
              "      <td>1.28</td>\n",
              "      <td>2.71</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.96</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.12</td>\n",
              "      <td>3.83</td>\n",
              "      <td>5.10</td>\n",
              "      <td>2.07</td>\n",
              "      <td>32.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94.73</td>\n",
              "      <td>16.26</td>\n",
              "      <td>29.43</td>\n",
              "      <td>24.05</td>\n",
              "      <td>27.35</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.88</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>6.13</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.47</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.97</td>\n",
              "      <td>39.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96.40</td>\n",
              "      <td>12.12</td>\n",
              "      <td>55.62</td>\n",
              "      <td>22.29</td>\n",
              "      <td>32.19</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.32</td>\n",
              "      <td>6.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.33</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.53</td>\n",
              "      <td>45.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96.29</td>\n",
              "      <td>22.73</td>\n",
              "      <td>15.88</td>\n",
              "      <td>22.05</td>\n",
              "      <td>27.21</td>\n",
              "      <td>4.19</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.86</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.81</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.93</td>\n",
              "      <td>3.49</td>\n",
              "      <td>5.47</td>\n",
              "      <td>0.23</td>\n",
              "      <td>50.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44873</th>\n",
              "      <td>96.34</td>\n",
              "      <td>16.74</td>\n",
              "      <td>46.26</td>\n",
              "      <td>49.00</td>\n",
              "      <td>28.01</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2.04</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.78</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.37</td>\n",
              "      <td>5.19</td>\n",
              "      <td>3.71</td>\n",
              "      <td>0.37</td>\n",
              "      <td>22.35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44874</th>\n",
              "      <td>94.03</td>\n",
              "      <td>14.89</td>\n",
              "      <td>56.75</td>\n",
              "      <td>27.73</td>\n",
              "      <td>19.02</td>\n",
              "      <td>3.28</td>\n",
              "      <td>1.97</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.30</td>\n",
              "      <td>5.57</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.93</td>\n",
              "      <td>6.23</td>\n",
              "      <td>0.98</td>\n",
              "      <td>51.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44875</th>\n",
              "      <td>90.88</td>\n",
              "      <td>33.24</td>\n",
              "      <td>22.15</td>\n",
              "      <td>38.88</td>\n",
              "      <td>22.66</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.99</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.71</td>\n",
              "      <td>2.22</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.68</td>\n",
              "      <td>4.68</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.03</td>\n",
              "      <td>2.83</td>\n",
              "      <td>5.94</td>\n",
              "      <td>1.52</td>\n",
              "      <td>28.24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44876</th>\n",
              "      <td>91.99</td>\n",
              "      <td>25.14</td>\n",
              "      <td>49.16</td>\n",
              "      <td>47.70</td>\n",
              "      <td>20.34</td>\n",
              "      <td>4.40</td>\n",
              "      <td>2.31</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1.26</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2.10</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.77</td>\n",
              "      <td>7.13</td>\n",
              "      <td>0.84</td>\n",
              "      <td>27.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44877</th>\n",
              "      <td>95.49</td>\n",
              "      <td>21.45</td>\n",
              "      <td>10.28</td>\n",
              "      <td>35.68</td>\n",
              "      <td>23.54</td>\n",
              "      <td>1.23</td>\n",
              "      <td>1.35</td>\n",
              "      <td>1.01</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.23</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.79</td>\n",
              "      <td>4.48</td>\n",
              "      <td>6.61</td>\n",
              "      <td>1.46</td>\n",
              "      <td>48.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44878 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Analytic  Authentic   Tone  ...  focusfuture  FREScore  target\n",
              "0         97.02      22.27  35.07  ...         2.00     42.04       1\n",
              "1         96.86      13.98  49.52  ...         2.07     32.57       1\n",
              "2         94.73      16.26  29.43  ...         1.97     39.91       1\n",
              "3         96.40      12.12  55.62  ...         0.53     45.49       1\n",
              "4         96.29      22.73  15.88  ...         0.23     50.80       1\n",
              "...         ...        ...    ...  ...          ...       ...     ...\n",
              "44873     96.34      16.74  46.26  ...         0.37     22.35       0\n",
              "44874     94.03      14.89  56.75  ...         0.98     51.41       0\n",
              "44875     90.88      33.24  22.15  ...         1.52     28.24       0\n",
              "44876     91.99      25.14  49.16  ...         0.84     27.16       0\n",
              "44877     95.49      21.45  10.28  ...         1.46     48.88       0\n",
              "\n",
              "[44878 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6BMAzqr7HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337f1648-626e-46aa-e670-972de06a95c4"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28721 train examples\n",
            "7181 validation examples\n",
            "8976 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996DerhILYBH"
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCPKp6yLYC6"
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjIBZEpLYHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b10b58-e9bc-4a92-eb8f-424c43176c2e"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  \n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']\n",
            "A batch of targets: tf.Tensor([0 1 1 1 0], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0af_RDSnLYJK"
      },
      "source": [
        "# We will use this batch to demonstrate several types of feature columns\n",
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_brV78bqLYMS"
      },
      "source": [
        "# A utility method to create a feature column\n",
        "# and to transform a batch of data\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm_Zw8fCLYN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa7e638-5ac0-494f-d424-c2f233474e3d"
      },
      "source": [
        "photo_count = feature_column.numeric_column('quant')\n",
        "demo(photo_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.93]\n",
            " [1.29]\n",
            " [0.  ]\n",
            " [1.44]\n",
            " [1.41]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-NKfHMLYSH"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs_xrFZzLYUe"
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoFfxHYjLYXv"
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONnCnqa0Ry8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b516d0-8474-4c1c-878a-468ca3b502e5"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(.1),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "884/898 [============================>.] - ETA: 0s - loss: 0.4180 - accuracy: 0.8406WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "898/898 [==============================] - 4s 3ms/step - loss: 0.4156 - accuracy: 0.8414 - val_loss: 0.3101 - val_accuracy: 0.8621\n",
            "Epoch 2/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2910 - accuracy: 0.8796 - val_loss: 0.2795 - val_accuracy: 0.8765\n",
            "Epoch 3/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2791 - accuracy: 0.8847 - val_loss: 0.2768 - val_accuracy: 0.8912\n",
            "Epoch 4/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2729 - accuracy: 0.8864 - val_loss: 0.2930 - val_accuracy: 0.8652\n",
            "Epoch 5/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2621 - accuracy: 0.8905 - val_loss: 0.2863 - val_accuracy: 0.8627\n",
            "Epoch 6/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2601 - accuracy: 0.8890 - val_loss: 0.2683 - val_accuracy: 0.8954\n",
            "Epoch 7/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2540 - accuracy: 0.8927 - val_loss: 0.2629 - val_accuracy: 0.8886\n",
            "Epoch 8/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2499 - accuracy: 0.8961 - val_loss: 0.2574 - val_accuracy: 0.8846\n",
            "Epoch 9/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2487 - accuracy: 0.8961 - val_loss: 0.2611 - val_accuracy: 0.8972\n",
            "Epoch 10/10\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2469 - accuracy: 0.8978 - val_loss: 0.2608 - val_accuracy: 0.8939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa02a993510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgG_OvFaRy-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98170789-c730-4a50-c9c1-6fc2f84d9205"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.8925\n",
            "Accuracy 0.8924911022186279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3euXS38oRzDV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEF8ts_NuElq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWq_Pk8jzZk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbsf8uil-7e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvnOx5-Yl-9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLWDkgdzl_B2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T6QaaTtx0IC",
        "outputId": "9d542b06-eba9-4711-8385-44228a0dbc7c"
      },
      "source": [
        "# fit model on training data with default hyperparameters\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HflGlD8-tztD"
      },
      "source": [
        "predicted = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_RTs2HXvzWF",
        "outputId": "bcacf066-ac10-444a-8fa1-85e6a3500281"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6327  730]\n",
            " [ 569 5838]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUGoLiLv3u3",
        "outputId": "1f46b4b7-a731-4cfa-ef24-f3d2f87df635"
      },
      "source": [
        "print(metrics.classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      7057\n",
            "           1       0.89      0.91      0.90      6407\n",
            "\n",
            "    accuracy                           0.90     13464\n",
            "   macro avg       0.90      0.90      0.90     13464\n",
            "weighted avg       0.90      0.90      0.90     13464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08vmvZGuv6WA",
        "outputId": "a64711c8-0afe-41fc-d2ef-6d9c6c92cc5d"
      },
      "source": [
        "print(model.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9035204991087344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Pt2EDq5j5r"
      },
      "source": [
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "J3Pol3Mm5b8F",
        "outputId": "d8fe4981-7eef-4345-953e-8b6addc766eb"
      },
      "source": [
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.28037\n",
            "Feature: 1, Score: 0.02999\n",
            "Feature: 2, Score: 0.01616\n",
            "Feature: 3, Score: 0.08011\n",
            "Feature: 4, Score: 0.13580\n",
            "Feature: 5, Score: 0.02910\n",
            "Feature: 6, Score: 0.06972\n",
            "Feature: 7, Score: 0.00729\n",
            "Feature: 8, Score: 0.01988\n",
            "Feature: 9, Score: 0.03163\n",
            "Feature: 10, Score: 0.06949\n",
            "Feature: 11, Score: 0.03174\n",
            "Feature: 12, Score: 0.03996\n",
            "Feature: 13, Score: 0.02159\n",
            "Feature: 14, Score: 0.01274\n",
            "Feature: 15, Score: 0.04637\n",
            "Feature: 16, Score: 0.01136\n",
            "Feature: 17, Score: 0.02749\n",
            "Feature: 18, Score: 0.03920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5SZqPg5cGC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSMFyT5y9jab"
      },
      "source": [
        "\n",
        "param_grid = {\n",
        "    'max_depth': [5,8,10],\n",
        "    'n_estimators': [50,100,150,],\n",
        "    'learning_rate': [0.1, 0.01, 0.05],\n",
        "    'subsample': [ 0.6, 1]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlA5yEk6yqrq"
      },
      "source": [
        "## **Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUJnsh5yo-v"
      },
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 10\n",
        "\n",
        "# specify range of hyperparameters\n",
        "#param_grid = {'learning_rate': [0.1,0.5], \n",
        "             #'subsample': [ 0.6, 1]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid,                          \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZzDqkM_9if-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_C4nkawzStC",
        "outputId": "26019827-982e-4aae-9c2f-7a5850cc9053"
      },
      "source": [
        "# fit the model\n",
        "model_cv.fit(X_train, y_train)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed: 79.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:logistic',\n",
              "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=None, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
              "                         'max_depth': [5, 8, 10],\n",
              "                         'n_estimators': [50, 100, 150],\n",
              "                         'subsample': [0.6, 1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LqpnK93-zTq6",
        "outputId": "792443a8-48fd-4f0b-ddb2-5459f03cc338"
      },
      "source": [
        "\n",
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_subsample</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>split3_train_score</th>\n",
              "      <th>split4_train_score</th>\n",
              "      <th>split5_train_score</th>\n",
              "      <th>split6_train_score</th>\n",
              "      <th>split7_train_score</th>\n",
              "      <th>split8_train_score</th>\n",
              "      <th>split9_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.587727</td>\n",
              "      <td>0.049830</td>\n",
              "      <td>0.012292</td>\n",
              "      <td>0.000856</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.913113</td>\n",
              "      <td>0.907384</td>\n",
              "      <td>0.914067</td>\n",
              "      <td>0.919796</td>\n",
              "      <td>0.909901</td>\n",
              "      <td>0.907036</td>\n",
              "      <td>0.913085</td>\n",
              "      <td>0.901942</td>\n",
              "      <td>0.913403</td>\n",
              "      <td>0.906399</td>\n",
              "      <td>0.910613</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>36</td>\n",
              "      <td>0.924484</td>\n",
              "      <td>0.922998</td>\n",
              "      <td>0.922750</td>\n",
              "      <td>0.922892</td>\n",
              "      <td>0.922258</td>\n",
              "      <td>0.923142</td>\n",
              "      <td>0.923001</td>\n",
              "      <td>0.923708</td>\n",
              "      <td>0.922187</td>\n",
              "      <td>0.924981</td>\n",
              "      <td>0.923240</td>\n",
              "      <td>0.000858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.222049</td>\n",
              "      <td>0.018294</td>\n",
              "      <td>0.011827</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.909612</td>\n",
              "      <td>0.907702</td>\n",
              "      <td>0.914704</td>\n",
              "      <td>0.917250</td>\n",
              "      <td>0.909901</td>\n",
              "      <td>0.907673</td>\n",
              "      <td>0.908309</td>\n",
              "      <td>0.901624</td>\n",
              "      <td>0.910538</td>\n",
              "      <td>0.905444</td>\n",
              "      <td>0.909276</td>\n",
              "      <td>0.004176</td>\n",
              "      <td>37</td>\n",
              "      <td>0.925368</td>\n",
              "      <td>0.924590</td>\n",
              "      <td>0.923529</td>\n",
              "      <td>0.923741</td>\n",
              "      <td>0.924133</td>\n",
              "      <td>0.924380</td>\n",
              "      <td>0.923991</td>\n",
              "      <td>0.924026</td>\n",
              "      <td>0.923461</td>\n",
              "      <td>0.925441</td>\n",
              "      <td>0.924266</td>\n",
              "      <td>0.000658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.961192</td>\n",
              "      <td>0.020051</td>\n",
              "      <td>0.021325</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.915977</td>\n",
              "      <td>0.918523</td>\n",
              "      <td>0.922979</td>\n",
              "      <td>0.928071</td>\n",
              "      <td>0.921363</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.914358</td>\n",
              "      <td>0.921999</td>\n",
              "      <td>0.914358</td>\n",
              "      <td>0.919653</td>\n",
              "      <td>0.004079</td>\n",
              "      <td>24</td>\n",
              "      <td>0.938632</td>\n",
              "      <td>0.936863</td>\n",
              "      <td>0.937146</td>\n",
              "      <td>0.936580</td>\n",
              "      <td>0.937255</td>\n",
              "      <td>0.938599</td>\n",
              "      <td>0.938210</td>\n",
              "      <td>0.938599</td>\n",
              "      <td>0.937538</td>\n",
              "      <td>0.939200</td>\n",
              "      <td>0.937862</td>\n",
              "      <td>0.000849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.270570</td>\n",
              "      <td>0.033783</td>\n",
              "      <td>0.021544</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.917887</td>\n",
              "      <td>0.918205</td>\n",
              "      <td>0.922024</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.921999</td>\n",
              "      <td>0.917224</td>\n",
              "      <td>0.914040</td>\n",
              "      <td>0.913403</td>\n",
              "      <td>0.918497</td>\n",
              "      <td>0.914040</td>\n",
              "      <td>0.918412</td>\n",
              "      <td>0.004016</td>\n",
              "      <td>26</td>\n",
              "      <td>0.939375</td>\n",
              "      <td>0.940153</td>\n",
              "      <td>0.938667</td>\n",
              "      <td>0.938137</td>\n",
              "      <td>0.938599</td>\n",
              "      <td>0.938705</td>\n",
              "      <td>0.938493</td>\n",
              "      <td>0.939660</td>\n",
              "      <td>0.939094</td>\n",
              "      <td>0.940438</td>\n",
              "      <td>0.939132</td>\n",
              "      <td>0.000719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.240818</td>\n",
              "      <td>0.021867</td>\n",
              "      <td>0.030830</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.919478</td>\n",
              "      <td>0.920751</td>\n",
              "      <td>0.924252</td>\n",
              "      <td>0.932209</td>\n",
              "      <td>0.923273</td>\n",
              "      <td>0.923591</td>\n",
              "      <td>0.923273</td>\n",
              "      <td>0.916905</td>\n",
              "      <td>0.925820</td>\n",
              "      <td>0.919134</td>\n",
              "      <td>0.922869</td>\n",
              "      <td>0.004052</td>\n",
              "      <td>17</td>\n",
              "      <td>0.946307</td>\n",
              "      <td>0.946555</td>\n",
              "      <td>0.946626</td>\n",
              "      <td>0.947156</td>\n",
              "      <td>0.946521</td>\n",
              "      <td>0.947689</td>\n",
              "      <td>0.946910</td>\n",
              "      <td>0.947618</td>\n",
              "      <td>0.946486</td>\n",
              "      <td>0.948042</td>\n",
              "      <td>0.946991</td>\n",
              "      <td>0.000573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.139449</td>\n",
              "      <td>0.024851</td>\n",
              "      <td>0.030259</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
              "      <td>0.918842</td>\n",
              "      <td>0.919796</td>\n",
              "      <td>0.922661</td>\n",
              "      <td>0.930617</td>\n",
              "      <td>0.923273</td>\n",
              "      <td>0.920408</td>\n",
              "      <td>0.918816</td>\n",
              "      <td>0.916905</td>\n",
              "      <td>0.923910</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.921309</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>20</td>\n",
              "      <td>0.947121</td>\n",
              "      <td>0.947333</td>\n",
              "      <td>0.946909</td>\n",
              "      <td>0.947156</td>\n",
              "      <td>0.947830</td>\n",
              "      <td>0.946804</td>\n",
              "      <td>0.947547</td>\n",
              "      <td>0.947936</td>\n",
              "      <td>0.947865</td>\n",
              "      <td>0.948396</td>\n",
              "      <td>0.947490</td>\n",
              "      <td>0.000486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.769385</td>\n",
              "      <td>0.018682</td>\n",
              "      <td>0.017957</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.919160</td>\n",
              "      <td>0.922024</td>\n",
              "      <td>0.925843</td>\n",
              "      <td>0.928071</td>\n",
              "      <td>0.920089</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.920408</td>\n",
              "      <td>0.914040</td>\n",
              "      <td>0.920408</td>\n",
              "      <td>0.914995</td>\n",
              "      <td>0.920608</td>\n",
              "      <td>0.004030</td>\n",
              "      <td>23</td>\n",
              "      <td>0.958298</td>\n",
              "      <td>0.956883</td>\n",
              "      <td>0.959147</td>\n",
              "      <td>0.957520</td>\n",
              "      <td>0.957734</td>\n",
              "      <td>0.958370</td>\n",
              "      <td>0.957451</td>\n",
              "      <td>0.957486</td>\n",
              "      <td>0.956602</td>\n",
              "      <td>0.958158</td>\n",
              "      <td>0.957765</td>\n",
              "      <td>0.000713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.437964</td>\n",
              "      <td>0.029723</td>\n",
              "      <td>0.017698</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.921706</td>\n",
              "      <td>0.920751</td>\n",
              "      <td>0.923934</td>\n",
              "      <td>0.927753</td>\n",
              "      <td>0.920408</td>\n",
              "      <td>0.919134</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.914677</td>\n",
              "      <td>0.925183</td>\n",
              "      <td>0.915314</td>\n",
              "      <td>0.920990</td>\n",
              "      <td>0.003853</td>\n",
              "      <td>21</td>\n",
              "      <td>0.964276</td>\n",
              "      <td>0.965160</td>\n",
              "      <td>0.964205</td>\n",
              "      <td>0.963780</td>\n",
              "      <td>0.963676</td>\n",
              "      <td>0.963393</td>\n",
              "      <td>0.963711</td>\n",
              "      <td>0.963004</td>\n",
              "      <td>0.963676</td>\n",
              "      <td>0.963852</td>\n",
              "      <td>0.963873</td>\n",
              "      <td>0.000550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.079178</td>\n",
              "      <td>0.053835</td>\n",
              "      <td>0.033599</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.926162</td>\n",
              "      <td>0.929981</td>\n",
              "      <td>0.935710</td>\n",
              "      <td>0.936346</td>\n",
              "      <td>0.927730</td>\n",
              "      <td>0.925501</td>\n",
              "      <td>0.929004</td>\n",
              "      <td>0.927730</td>\n",
              "      <td>0.928685</td>\n",
              "      <td>0.923910</td>\n",
              "      <td>0.929076</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>9</td>\n",
              "      <td>0.979202</td>\n",
              "      <td>0.978282</td>\n",
              "      <td>0.977787</td>\n",
              "      <td>0.977257</td>\n",
              "      <td>0.978601</td>\n",
              "      <td>0.978389</td>\n",
              "      <td>0.979026</td>\n",
              "      <td>0.977576</td>\n",
              "      <td>0.977505</td>\n",
              "      <td>0.978495</td>\n",
              "      <td>0.978212</td>\n",
              "      <td>0.000625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8.168818</td>\n",
              "      <td>0.082902</td>\n",
              "      <td>0.033274</td>\n",
              "      <td>0.000835</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.925207</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.934437</td>\n",
              "      <td>0.935391</td>\n",
              "      <td>0.931869</td>\n",
              "      <td>0.928685</td>\n",
              "      <td>0.927730</td>\n",
              "      <td>0.922954</td>\n",
              "      <td>0.931869</td>\n",
              "      <td>0.922636</td>\n",
              "      <td>0.928758</td>\n",
              "      <td>0.004293</td>\n",
              "      <td>10</td>\n",
              "      <td>0.981926</td>\n",
              "      <td>0.982315</td>\n",
              "      <td>0.979202</td>\n",
              "      <td>0.981324</td>\n",
              "      <td>0.981785</td>\n",
              "      <td>0.979203</td>\n",
              "      <td>0.980688</td>\n",
              "      <td>0.979663</td>\n",
              "      <td>0.979592</td>\n",
              "      <td>0.981749</td>\n",
              "      <td>0.980745</td>\n",
              "      <td>0.001164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>13.357159</td>\n",
              "      <td>0.058490</td>\n",
              "      <td>0.049029</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.928390</td>\n",
              "      <td>0.934118</td>\n",
              "      <td>0.939529</td>\n",
              "      <td>0.940165</td>\n",
              "      <td>0.936326</td>\n",
              "      <td>0.930914</td>\n",
              "      <td>0.936326</td>\n",
              "      <td>0.931869</td>\n",
              "      <td>0.933142</td>\n",
              "      <td>0.930595</td>\n",
              "      <td>0.934137</td>\n",
              "      <td>0.003703</td>\n",
              "      <td>5</td>\n",
              "      <td>0.990733</td>\n",
              "      <td>0.991122</td>\n",
              "      <td>0.990415</td>\n",
              "      <td>0.990132</td>\n",
              "      <td>0.991653</td>\n",
              "      <td>0.990450</td>\n",
              "      <td>0.991087</td>\n",
              "      <td>0.990026</td>\n",
              "      <td>0.989778</td>\n",
              "      <td>0.990486</td>\n",
              "      <td>0.990588</td>\n",
              "      <td>0.000541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11.764528</td>\n",
              "      <td>0.078668</td>\n",
              "      <td>0.047909</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>0.1</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
              "      <td>0.928390</td>\n",
              "      <td>0.932209</td>\n",
              "      <td>0.938574</td>\n",
              "      <td>0.938256</td>\n",
              "      <td>0.936326</td>\n",
              "      <td>0.932187</td>\n",
              "      <td>0.933142</td>\n",
              "      <td>0.928048</td>\n",
              "      <td>0.932824</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.932705</td>\n",
              "      <td>0.003884</td>\n",
              "      <td>6</td>\n",
              "      <td>0.989566</td>\n",
              "      <td>0.990839</td>\n",
              "      <td>0.989813</td>\n",
              "      <td>0.990627</td>\n",
              "      <td>0.989778</td>\n",
              "      <td>0.990061</td>\n",
              "      <td>0.989920</td>\n",
              "      <td>0.989177</td>\n",
              "      <td>0.988753</td>\n",
              "      <td>0.990804</td>\n",
              "      <td>0.989934</td>\n",
              "      <td>0.000649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.310281</td>\n",
              "      <td>0.026760</td>\n",
              "      <td>0.021903</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.926162</td>\n",
              "      <td>0.932845</td>\n",
              "      <td>0.932845</td>\n",
              "      <td>0.932209</td>\n",
              "      <td>0.926775</td>\n",
              "      <td>0.923910</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.918179</td>\n",
              "      <td>0.928048</td>\n",
              "      <td>0.926138</td>\n",
              "      <td>0.927420</td>\n",
              "      <td>0.004286</td>\n",
              "      <td>14</td>\n",
              "      <td>0.978530</td>\n",
              "      <td>0.978212</td>\n",
              "      <td>0.977080</td>\n",
              "      <td>0.976620</td>\n",
              "      <td>0.978212</td>\n",
              "      <td>0.979309</td>\n",
              "      <td>0.978212</td>\n",
              "      <td>0.977470</td>\n",
              "      <td>0.978743</td>\n",
              "      <td>0.978708</td>\n",
              "      <td>0.978110</td>\n",
              "      <td>0.000781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.123533</td>\n",
              "      <td>0.026038</td>\n",
              "      <td>0.021695</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.928708</td>\n",
              "      <td>0.936028</td>\n",
              "      <td>0.934118</td>\n",
              "      <td>0.930277</td>\n",
              "      <td>0.925183</td>\n",
              "      <td>0.927730</td>\n",
              "      <td>0.922318</td>\n",
              "      <td>0.927730</td>\n",
              "      <td>0.919452</td>\n",
              "      <td>0.927834</td>\n",
              "      <td>0.004713</td>\n",
              "      <td>13</td>\n",
              "      <td>0.986948</td>\n",
              "      <td>0.987019</td>\n",
              "      <td>0.986984</td>\n",
              "      <td>0.985746</td>\n",
              "      <td>0.986772</td>\n",
              "      <td>0.985746</td>\n",
              "      <td>0.986595</td>\n",
              "      <td>0.985605</td>\n",
              "      <td>0.986135</td>\n",
              "      <td>0.987161</td>\n",
              "      <td>0.986471</td>\n",
              "      <td>0.000573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11.945802</td>\n",
              "      <td>0.048568</td>\n",
              "      <td>0.040921</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.933482</td>\n",
              "      <td>0.935073</td>\n",
              "      <td>0.937938</td>\n",
              "      <td>0.937619</td>\n",
              "      <td>0.937281</td>\n",
              "      <td>0.935053</td>\n",
              "      <td>0.933142</td>\n",
              "      <td>0.930277</td>\n",
              "      <td>0.932824</td>\n",
              "      <td>0.933461</td>\n",
              "      <td>0.934615</td>\n",
              "      <td>0.002332</td>\n",
              "      <td>4</td>\n",
              "      <td>0.993244</td>\n",
              "      <td>0.993173</td>\n",
              "      <td>0.993846</td>\n",
              "      <td>0.993881</td>\n",
              "      <td>0.993740</td>\n",
              "      <td>0.994058</td>\n",
              "      <td>0.993209</td>\n",
              "      <td>0.993244</td>\n",
              "      <td>0.993634</td>\n",
              "      <td>0.993704</td>\n",
              "      <td>0.993573</td>\n",
              "      <td>0.000310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11.186296</td>\n",
              "      <td>0.086230</td>\n",
              "      <td>0.040706</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.931891</td>\n",
              "      <td>0.936028</td>\n",
              "      <td>0.941757</td>\n",
              "      <td>0.937619</td>\n",
              "      <td>0.942057</td>\n",
              "      <td>0.932506</td>\n",
              "      <td>0.936644</td>\n",
              "      <td>0.929322</td>\n",
              "      <td>0.935371</td>\n",
              "      <td>0.928685</td>\n",
              "      <td>0.935188</td>\n",
              "      <td>0.004403</td>\n",
              "      <td>3</td>\n",
              "      <td>0.995791</td>\n",
              "      <td>0.996038</td>\n",
              "      <td>0.995968</td>\n",
              "      <td>0.995366</td>\n",
              "      <td>0.995826</td>\n",
              "      <td>0.995968</td>\n",
              "      <td>0.996251</td>\n",
              "      <td>0.995473</td>\n",
              "      <td>0.995791</td>\n",
              "      <td>0.996428</td>\n",
              "      <td>0.995890</td>\n",
              "      <td>0.000304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17.481073</td>\n",
              "      <td>0.055557</td>\n",
              "      <td>0.061055</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.935073</td>\n",
              "      <td>0.936665</td>\n",
              "      <td>0.939847</td>\n",
              "      <td>0.939211</td>\n",
              "      <td>0.938873</td>\n",
              "      <td>0.936644</td>\n",
              "      <td>0.938236</td>\n",
              "      <td>0.935053</td>\n",
              "      <td>0.938236</td>\n",
              "      <td>0.937918</td>\n",
              "      <td>0.937576</td>\n",
              "      <td>0.001576</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999045</td>\n",
              "      <td>0.998514</td>\n",
              "      <td>0.998762</td>\n",
              "      <td>0.998868</td>\n",
              "      <td>0.998691</td>\n",
              "      <td>0.998797</td>\n",
              "      <td>0.998585</td>\n",
              "      <td>0.998762</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>0.998691</td>\n",
              "      <td>0.998734</td>\n",
              "      <td>0.000144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16.145331</td>\n",
              "      <td>0.187300</td>\n",
              "      <td>0.061470</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
              "      <td>0.937301</td>\n",
              "      <td>0.936346</td>\n",
              "      <td>0.942393</td>\n",
              "      <td>0.941757</td>\n",
              "      <td>0.941102</td>\n",
              "      <td>0.937599</td>\n",
              "      <td>0.939510</td>\n",
              "      <td>0.932187</td>\n",
              "      <td>0.942375</td>\n",
              "      <td>0.934416</td>\n",
              "      <td>0.938499</td>\n",
              "      <td>0.003346</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999469</td>\n",
              "      <td>0.999080</td>\n",
              "      <td>0.998833</td>\n",
              "      <td>0.999080</td>\n",
              "      <td>0.999399</td>\n",
              "      <td>0.999257</td>\n",
              "      <td>0.999257</td>\n",
              "      <td>0.999151</td>\n",
              "      <td>0.999080</td>\n",
              "      <td>0.999434</td>\n",
              "      <td>0.999204</td>\n",
              "      <td>0.000188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.484758</td>\n",
              "      <td>0.015362</td>\n",
              "      <td>0.009603</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.875875</td>\n",
              "      <td>0.875557</td>\n",
              "      <td>0.870465</td>\n",
              "      <td>0.868873</td>\n",
              "      <td>0.869150</td>\n",
              "      <td>0.875836</td>\n",
              "      <td>0.870742</td>\n",
              "      <td>0.864693</td>\n",
              "      <td>0.861827</td>\n",
              "      <td>0.870423</td>\n",
              "      <td>0.870344</td>\n",
              "      <td>0.004429</td>\n",
              "      <td>53</td>\n",
              "      <td>0.874434</td>\n",
              "      <td>0.876804</td>\n",
              "      <td>0.875318</td>\n",
              "      <td>0.875035</td>\n",
              "      <td>0.875818</td>\n",
              "      <td>0.877020</td>\n",
              "      <td>0.874757</td>\n",
              "      <td>0.878612</td>\n",
              "      <td>0.875783</td>\n",
              "      <td>0.876879</td>\n",
              "      <td>0.876046</td>\n",
              "      <td>0.001214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.142451</td>\n",
              "      <td>0.009055</td>\n",
              "      <td>0.009426</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.875239</td>\n",
              "      <td>0.870783</td>\n",
              "      <td>0.870146</td>\n",
              "      <td>0.864099</td>\n",
              "      <td>0.866285</td>\n",
              "      <td>0.871697</td>\n",
              "      <td>0.868195</td>\n",
              "      <td>0.863101</td>\n",
              "      <td>0.865330</td>\n",
              "      <td>0.862146</td>\n",
              "      <td>0.867702</td>\n",
              "      <td>0.004014</td>\n",
              "      <td>54</td>\n",
              "      <td>0.873904</td>\n",
              "      <td>0.872453</td>\n",
              "      <td>0.874186</td>\n",
              "      <td>0.873656</td>\n",
              "      <td>0.875570</td>\n",
              "      <td>0.876278</td>\n",
              "      <td>0.873873</td>\n",
              "      <td>0.878294</td>\n",
              "      <td>0.875889</td>\n",
              "      <td>0.875287</td>\n",
              "      <td>0.874939</td>\n",
              "      <td>0.001583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4.942250</td>\n",
              "      <td>0.014930</td>\n",
              "      <td>0.016714</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.885423</td>\n",
              "      <td>0.880649</td>\n",
              "      <td>0.880649</td>\n",
              "      <td>0.878103</td>\n",
              "      <td>0.877109</td>\n",
              "      <td>0.877428</td>\n",
              "      <td>0.882521</td>\n",
              "      <td>0.867558</td>\n",
              "      <td>0.870423</td>\n",
              "      <td>0.875517</td>\n",
              "      <td>0.877538</td>\n",
              "      <td>0.005111</td>\n",
              "      <td>51</td>\n",
              "      <td>0.883418</td>\n",
              "      <td>0.884515</td>\n",
              "      <td>0.884692</td>\n",
              "      <td>0.884196</td>\n",
              "      <td>0.884130</td>\n",
              "      <td>0.885226</td>\n",
              "      <td>0.884307</td>\n",
              "      <td>0.887596</td>\n",
              "      <td>0.885474</td>\n",
              "      <td>0.886323</td>\n",
              "      <td>0.884988</td>\n",
              "      <td>0.001161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.279927</td>\n",
              "      <td>0.019234</td>\n",
              "      <td>0.016211</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.882877</td>\n",
              "      <td>0.878421</td>\n",
              "      <td>0.880013</td>\n",
              "      <td>0.874284</td>\n",
              "      <td>0.877428</td>\n",
              "      <td>0.879975</td>\n",
              "      <td>0.882521</td>\n",
              "      <td>0.870105</td>\n",
              "      <td>0.869787</td>\n",
              "      <td>0.874562</td>\n",
              "      <td>0.876997</td>\n",
              "      <td>0.004450</td>\n",
              "      <td>52</td>\n",
              "      <td>0.884232</td>\n",
              "      <td>0.884939</td>\n",
              "      <td>0.884020</td>\n",
              "      <td>0.885576</td>\n",
              "      <td>0.884554</td>\n",
              "      <td>0.885969</td>\n",
              "      <td>0.884943</td>\n",
              "      <td>0.886995</td>\n",
              "      <td>0.885297</td>\n",
              "      <td>0.885509</td>\n",
              "      <td>0.885203</td>\n",
              "      <td>0.000833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7.401674</td>\n",
              "      <td>0.017359</td>\n",
              "      <td>0.024207</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.891152</td>\n",
              "      <td>0.885742</td>\n",
              "      <td>0.887651</td>\n",
              "      <td>0.884150</td>\n",
              "      <td>0.886342</td>\n",
              "      <td>0.883795</td>\n",
              "      <td>0.892709</td>\n",
              "      <td>0.872652</td>\n",
              "      <td>0.878383</td>\n",
              "      <td>0.884750</td>\n",
              "      <td>0.884733</td>\n",
              "      <td>0.005518</td>\n",
              "      <td>50</td>\n",
              "      <td>0.893145</td>\n",
              "      <td>0.894136</td>\n",
              "      <td>0.892615</td>\n",
              "      <td>0.893322</td>\n",
              "      <td>0.892300</td>\n",
              "      <td>0.893892</td>\n",
              "      <td>0.892335</td>\n",
              "      <td>0.894139</td>\n",
              "      <td>0.893078</td>\n",
              "      <td>0.894422</td>\n",
              "      <td>0.893338</td>\n",
              "      <td>0.000740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.404302</td>\n",
              "      <td>0.019687</td>\n",
              "      <td>0.023279</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.888606</td>\n",
              "      <td>0.887651</td>\n",
              "      <td>0.888924</td>\n",
              "      <td>0.882241</td>\n",
              "      <td>0.887297</td>\n",
              "      <td>0.882840</td>\n",
              "      <td>0.890481</td>\n",
              "      <td>0.875836</td>\n",
              "      <td>0.880930</td>\n",
              "      <td>0.883477</td>\n",
              "      <td>0.884828</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>49</td>\n",
              "      <td>0.893640</td>\n",
              "      <td>0.893004</td>\n",
              "      <td>0.893251</td>\n",
              "      <td>0.892296</td>\n",
              "      <td>0.892583</td>\n",
              "      <td>0.893962</td>\n",
              "      <td>0.893432</td>\n",
              "      <td>0.895908</td>\n",
              "      <td>0.892760</td>\n",
              "      <td>0.894033</td>\n",
              "      <td>0.893487</td>\n",
              "      <td>0.000973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.731992</td>\n",
              "      <td>0.022676</td>\n",
              "      <td>0.015649</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.898472</td>\n",
              "      <td>0.897518</td>\n",
              "      <td>0.907702</td>\n",
              "      <td>0.901973</td>\n",
              "      <td>0.898440</td>\n",
              "      <td>0.898758</td>\n",
              "      <td>0.902579</td>\n",
              "      <td>0.887297</td>\n",
              "      <td>0.897167</td>\n",
              "      <td>0.890799</td>\n",
              "      <td>0.898070</td>\n",
              "      <td>0.005470</td>\n",
              "      <td>45</td>\n",
              "      <td>0.921654</td>\n",
              "      <td>0.919744</td>\n",
              "      <td>0.920593</td>\n",
              "      <td>0.920522</td>\n",
              "      <td>0.921055</td>\n",
              "      <td>0.921268</td>\n",
              "      <td>0.921834</td>\n",
              "      <td>0.922258</td>\n",
              "      <td>0.921798</td>\n",
              "      <td>0.922117</td>\n",
              "      <td>0.921284</td>\n",
              "      <td>0.000763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4.404850</td>\n",
              "      <td>0.020044</td>\n",
              "      <td>0.014989</td>\n",
              "      <td>0.000399</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.898472</td>\n",
              "      <td>0.896244</td>\n",
              "      <td>0.899427</td>\n",
              "      <td>0.895290</td>\n",
              "      <td>0.893028</td>\n",
              "      <td>0.894620</td>\n",
              "      <td>0.891754</td>\n",
              "      <td>0.887297</td>\n",
              "      <td>0.897167</td>\n",
              "      <td>0.883477</td>\n",
              "      <td>0.893678</td>\n",
              "      <td>0.004766</td>\n",
              "      <td>48</td>\n",
              "      <td>0.921300</td>\n",
              "      <td>0.921477</td>\n",
              "      <td>0.922821</td>\n",
              "      <td>0.920098</td>\n",
              "      <td>0.921621</td>\n",
              "      <td>0.920772</td>\n",
              "      <td>0.921055</td>\n",
              "      <td>0.921162</td>\n",
              "      <td>0.922470</td>\n",
              "      <td>0.922046</td>\n",
              "      <td>0.921482</td>\n",
              "      <td>0.000765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>9.459752</td>\n",
              "      <td>0.030713</td>\n",
              "      <td>0.028858</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.904838</td>\n",
              "      <td>0.904519</td>\n",
              "      <td>0.909930</td>\n",
              "      <td>0.909293</td>\n",
              "      <td>0.901942</td>\n",
              "      <td>0.899395</td>\n",
              "      <td>0.906718</td>\n",
              "      <td>0.893664</td>\n",
              "      <td>0.902897</td>\n",
              "      <td>0.895575</td>\n",
              "      <td>0.902877</td>\n",
              "      <td>0.005132</td>\n",
              "      <td>43</td>\n",
              "      <td>0.928480</td>\n",
              "      <td>0.926323</td>\n",
              "      <td>0.927915</td>\n",
              "      <td>0.926818</td>\n",
              "      <td>0.927387</td>\n",
              "      <td>0.927846</td>\n",
              "      <td>0.927952</td>\n",
              "      <td>0.927882</td>\n",
              "      <td>0.927740</td>\n",
              "      <td>0.928554</td>\n",
              "      <td>0.927690</td>\n",
              "      <td>0.000654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8.791057</td>\n",
              "      <td>0.049795</td>\n",
              "      <td>0.027149</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.906111</td>\n",
              "      <td>0.905156</td>\n",
              "      <td>0.906429</td>\n",
              "      <td>0.906747</td>\n",
              "      <td>0.902897</td>\n",
              "      <td>0.899395</td>\n",
              "      <td>0.901942</td>\n",
              "      <td>0.892709</td>\n",
              "      <td>0.902260</td>\n",
              "      <td>0.894620</td>\n",
              "      <td>0.901827</td>\n",
              "      <td>0.004660</td>\n",
              "      <td>44</td>\n",
              "      <td>0.931416</td>\n",
              "      <td>0.929153</td>\n",
              "      <td>0.930567</td>\n",
              "      <td>0.929400</td>\n",
              "      <td>0.930605</td>\n",
              "      <td>0.930782</td>\n",
              "      <td>0.930923</td>\n",
              "      <td>0.930075</td>\n",
              "      <td>0.929792</td>\n",
              "      <td>0.931878</td>\n",
              "      <td>0.930459</td>\n",
              "      <td>0.000819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>14.222011</td>\n",
              "      <td>0.034034</td>\n",
              "      <td>0.042849</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.908975</td>\n",
              "      <td>0.912158</td>\n",
              "      <td>0.910885</td>\n",
              "      <td>0.913431</td>\n",
              "      <td>0.907673</td>\n",
              "      <td>0.902260</td>\n",
              "      <td>0.907036</td>\n",
              "      <td>0.898122</td>\n",
              "      <td>0.907991</td>\n",
              "      <td>0.898758</td>\n",
              "      <td>0.906729</td>\n",
              "      <td>0.005068</td>\n",
              "      <td>40</td>\n",
              "      <td>0.934564</td>\n",
              "      <td>0.933468</td>\n",
              "      <td>0.933680</td>\n",
              "      <td>0.933715</td>\n",
              "      <td>0.933859</td>\n",
              "      <td>0.933824</td>\n",
              "      <td>0.933718</td>\n",
              "      <td>0.934177</td>\n",
              "      <td>0.934460</td>\n",
              "      <td>0.934920</td>\n",
              "      <td>0.934039</td>\n",
              "      <td>0.000446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>13.294674</td>\n",
              "      <td>0.047534</td>\n",
              "      <td>0.040625</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.01</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.909930</td>\n",
              "      <td>0.908020</td>\n",
              "      <td>0.909612</td>\n",
              "      <td>0.909612</td>\n",
              "      <td>0.907991</td>\n",
              "      <td>0.902579</td>\n",
              "      <td>0.904807</td>\n",
              "      <td>0.896211</td>\n",
              "      <td>0.908309</td>\n",
              "      <td>0.898758</td>\n",
              "      <td>0.905583</td>\n",
              "      <td>0.004632</td>\n",
              "      <td>41</td>\n",
              "      <td>0.937889</td>\n",
              "      <td>0.936368</td>\n",
              "      <td>0.937323</td>\n",
              "      <td>0.935201</td>\n",
              "      <td>0.936264</td>\n",
              "      <td>0.937078</td>\n",
              "      <td>0.936689</td>\n",
              "      <td>0.936583</td>\n",
              "      <td>0.936300</td>\n",
              "      <td>0.937538</td>\n",
              "      <td>0.936723</td>\n",
              "      <td>0.000732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>6.363148</td>\n",
              "      <td>0.024638</td>\n",
              "      <td>0.019972</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.906747</td>\n",
              "      <td>0.907384</td>\n",
              "      <td>0.917250</td>\n",
              "      <td>0.910567</td>\n",
              "      <td>0.907354</td>\n",
              "      <td>0.904171</td>\n",
              "      <td>0.909583</td>\n",
              "      <td>0.898122</td>\n",
              "      <td>0.906081</td>\n",
              "      <td>0.901624</td>\n",
              "      <td>0.906888</td>\n",
              "      <td>0.004912</td>\n",
              "      <td>39</td>\n",
              "      <td>0.943265</td>\n",
              "      <td>0.941744</td>\n",
              "      <td>0.942452</td>\n",
              "      <td>0.941320</td>\n",
              "      <td>0.943232</td>\n",
              "      <td>0.943267</td>\n",
              "      <td>0.943621</td>\n",
              "      <td>0.941923</td>\n",
              "      <td>0.941747</td>\n",
              "      <td>0.944258</td>\n",
              "      <td>0.942683</td>\n",
              "      <td>0.000927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>6.169450</td>\n",
              "      <td>0.034134</td>\n",
              "      <td>0.018795</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.904201</td>\n",
              "      <td>0.905474</td>\n",
              "      <td>0.912158</td>\n",
              "      <td>0.905474</td>\n",
              "      <td>0.903534</td>\n",
              "      <td>0.903852</td>\n",
              "      <td>0.901305</td>\n",
              "      <td>0.893983</td>\n",
              "      <td>0.908309</td>\n",
              "      <td>0.891436</td>\n",
              "      <td>0.902973</td>\n",
              "      <td>0.005871</td>\n",
              "      <td>42</td>\n",
              "      <td>0.950198</td>\n",
              "      <td>0.948430</td>\n",
              "      <td>0.949385</td>\n",
              "      <td>0.947864</td>\n",
              "      <td>0.948927</td>\n",
              "      <td>0.948820</td>\n",
              "      <td>0.949033</td>\n",
              "      <td>0.947724</td>\n",
              "      <td>0.947795</td>\n",
              "      <td>0.949174</td>\n",
              "      <td>0.948735</td>\n",
              "      <td>0.000751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>12.768636</td>\n",
              "      <td>0.047449</td>\n",
              "      <td>0.038374</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.911840</td>\n",
              "      <td>0.915341</td>\n",
              "      <td>0.918842</td>\n",
              "      <td>0.916295</td>\n",
              "      <td>0.909265</td>\n",
              "      <td>0.908946</td>\n",
              "      <td>0.912767</td>\n",
              "      <td>0.903534</td>\n",
              "      <td>0.911175</td>\n",
              "      <td>0.905762</td>\n",
              "      <td>0.911377</td>\n",
              "      <td>0.004486</td>\n",
              "      <td>33</td>\n",
              "      <td>0.950057</td>\n",
              "      <td>0.949066</td>\n",
              "      <td>0.949774</td>\n",
              "      <td>0.948960</td>\n",
              "      <td>0.949634</td>\n",
              "      <td>0.949740</td>\n",
              "      <td>0.949316</td>\n",
              "      <td>0.949033</td>\n",
              "      <td>0.949033</td>\n",
              "      <td>0.950129</td>\n",
              "      <td>0.949474</td>\n",
              "      <td>0.000424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>12.396803</td>\n",
              "      <td>0.083756</td>\n",
              "      <td>0.037892</td>\n",
              "      <td>0.001467</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.914067</td>\n",
              "      <td>0.915977</td>\n",
              "      <td>0.918205</td>\n",
              "      <td>0.915341</td>\n",
              "      <td>0.911175</td>\n",
              "      <td>0.911812</td>\n",
              "      <td>0.905762</td>\n",
              "      <td>0.900032</td>\n",
              "      <td>0.916905</td>\n",
              "      <td>0.902897</td>\n",
              "      <td>0.911217</td>\n",
              "      <td>0.005945</td>\n",
              "      <td>34</td>\n",
              "      <td>0.958050</td>\n",
              "      <td>0.958404</td>\n",
              "      <td>0.958970</td>\n",
              "      <td>0.957237</td>\n",
              "      <td>0.958335</td>\n",
              "      <td>0.957804</td>\n",
              "      <td>0.957627</td>\n",
              "      <td>0.957592</td>\n",
              "      <td>0.957274</td>\n",
              "      <td>0.957557</td>\n",
              "      <td>0.957885</td>\n",
              "      <td>0.000523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>19.062381</td>\n",
              "      <td>0.067844</td>\n",
              "      <td>0.061967</td>\n",
              "      <td>0.002152</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.916932</td>\n",
              "      <td>0.918523</td>\n",
              "      <td>0.922024</td>\n",
              "      <td>0.920751</td>\n",
              "      <td>0.913403</td>\n",
              "      <td>0.911812</td>\n",
              "      <td>0.913722</td>\n",
              "      <td>0.906081</td>\n",
              "      <td>0.916269</td>\n",
              "      <td>0.909265</td>\n",
              "      <td>0.914878</td>\n",
              "      <td>0.004763</td>\n",
              "      <td>30</td>\n",
              "      <td>0.956282</td>\n",
              "      <td>0.955716</td>\n",
              "      <td>0.954938</td>\n",
              "      <td>0.955115</td>\n",
              "      <td>0.956107</td>\n",
              "      <td>0.955824</td>\n",
              "      <td>0.955187</td>\n",
              "      <td>0.955010</td>\n",
              "      <td>0.954904</td>\n",
              "      <td>0.956000</td>\n",
              "      <td>0.955508</td>\n",
              "      <td>0.000504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>18.532152</td>\n",
              "      <td>0.098824</td>\n",
              "      <td>0.062775</td>\n",
              "      <td>0.005205</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.920115</td>\n",
              "      <td>0.921388</td>\n",
              "      <td>0.922661</td>\n",
              "      <td>0.920751</td>\n",
              "      <td>0.915632</td>\n",
              "      <td>0.912767</td>\n",
              "      <td>0.911493</td>\n",
              "      <td>0.906081</td>\n",
              "      <td>0.918179</td>\n",
              "      <td>0.909583</td>\n",
              "      <td>0.915865</td>\n",
              "      <td>0.005366</td>\n",
              "      <td>29</td>\n",
              "      <td>0.964665</td>\n",
              "      <td>0.964488</td>\n",
              "      <td>0.965231</td>\n",
              "      <td>0.962932</td>\n",
              "      <td>0.965090</td>\n",
              "      <td>0.964029</td>\n",
              "      <td>0.964843</td>\n",
              "      <td>0.963605</td>\n",
              "      <td>0.963959</td>\n",
              "      <td>0.965975</td>\n",
              "      <td>0.964482</td>\n",
              "      <td>0.000835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2.495075</td>\n",
              "      <td>0.010015</td>\n",
              "      <td>0.011105</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.896563</td>\n",
              "      <td>0.898791</td>\n",
              "      <td>0.900382</td>\n",
              "      <td>0.901337</td>\n",
              "      <td>0.893983</td>\n",
              "      <td>0.890799</td>\n",
              "      <td>0.903216</td>\n",
              "      <td>0.881885</td>\n",
              "      <td>0.895575</td>\n",
              "      <td>0.890162</td>\n",
              "      <td>0.895269</td>\n",
              "      <td>0.006059</td>\n",
              "      <td>46</td>\n",
              "      <td>0.904888</td>\n",
              "      <td>0.906055</td>\n",
              "      <td>0.904994</td>\n",
              "      <td>0.904322</td>\n",
              "      <td>0.904927</td>\n",
              "      <td>0.906306</td>\n",
              "      <td>0.905705</td>\n",
              "      <td>0.906731</td>\n",
              "      <td>0.904892</td>\n",
              "      <td>0.907757</td>\n",
              "      <td>0.905658</td>\n",
              "      <td>0.001004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2.163268</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.011002</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.898472</td>\n",
              "      <td>0.897518</td>\n",
              "      <td>0.897518</td>\n",
              "      <td>0.900064</td>\n",
              "      <td>0.894938</td>\n",
              "      <td>0.890799</td>\n",
              "      <td>0.898758</td>\n",
              "      <td>0.884432</td>\n",
              "      <td>0.894301</td>\n",
              "      <td>0.891754</td>\n",
              "      <td>0.894855</td>\n",
              "      <td>0.004524</td>\n",
              "      <td>47</td>\n",
              "      <td>0.905737</td>\n",
              "      <td>0.906091</td>\n",
              "      <td>0.905136</td>\n",
              "      <td>0.905490</td>\n",
              "      <td>0.905528</td>\n",
              "      <td>0.906660</td>\n",
              "      <td>0.905351</td>\n",
              "      <td>0.907933</td>\n",
              "      <td>0.905670</td>\n",
              "      <td>0.907474</td>\n",
              "      <td>0.906107</td>\n",
              "      <td>0.000898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.937597</td>\n",
              "      <td>0.013156</td>\n",
              "      <td>0.020767</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.908657</td>\n",
              "      <td>0.911203</td>\n",
              "      <td>0.913113</td>\n",
              "      <td>0.917250</td>\n",
              "      <td>0.910538</td>\n",
              "      <td>0.910856</td>\n",
              "      <td>0.910538</td>\n",
              "      <td>0.902579</td>\n",
              "      <td>0.915632</td>\n",
              "      <td>0.906718</td>\n",
              "      <td>0.910708</td>\n",
              "      <td>0.003992</td>\n",
              "      <td>35</td>\n",
              "      <td>0.924236</td>\n",
              "      <td>0.923599</td>\n",
              "      <td>0.923352</td>\n",
              "      <td>0.923246</td>\n",
              "      <td>0.922753</td>\n",
              "      <td>0.922612</td>\n",
              "      <td>0.923814</td>\n",
              "      <td>0.924663</td>\n",
              "      <td>0.923920</td>\n",
              "      <td>0.925901</td>\n",
              "      <td>0.923810</td>\n",
              "      <td>0.000918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>4.244409</td>\n",
              "      <td>0.014426</td>\n",
              "      <td>0.020015</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.908339</td>\n",
              "      <td>0.905792</td>\n",
              "      <td>0.913749</td>\n",
              "      <td>0.917568</td>\n",
              "      <td>0.908628</td>\n",
              "      <td>0.912130</td>\n",
              "      <td>0.909265</td>\n",
              "      <td>0.900350</td>\n",
              "      <td>0.909901</td>\n",
              "      <td>0.905126</td>\n",
              "      <td>0.909085</td>\n",
              "      <td>0.004553</td>\n",
              "      <td>38</td>\n",
              "      <td>0.925439</td>\n",
              "      <td>0.924943</td>\n",
              "      <td>0.924660</td>\n",
              "      <td>0.924448</td>\n",
              "      <td>0.925229</td>\n",
              "      <td>0.926007</td>\n",
              "      <td>0.924522</td>\n",
              "      <td>0.925158</td>\n",
              "      <td>0.924628</td>\n",
              "      <td>0.925830</td>\n",
              "      <td>0.925086</td>\n",
              "      <td>0.000519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>7.315270</td>\n",
              "      <td>0.021860</td>\n",
              "      <td>0.029349</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.914704</td>\n",
              "      <td>0.915977</td>\n",
              "      <td>0.919160</td>\n",
              "      <td>0.924889</td>\n",
              "      <td>0.919134</td>\n",
              "      <td>0.914040</td>\n",
              "      <td>0.913722</td>\n",
              "      <td>0.911175</td>\n",
              "      <td>0.921363</td>\n",
              "      <td>0.912448</td>\n",
              "      <td>0.916661</td>\n",
              "      <td>0.004121</td>\n",
              "      <td>27</td>\n",
              "      <td>0.932866</td>\n",
              "      <td>0.932654</td>\n",
              "      <td>0.931841</td>\n",
              "      <td>0.932371</td>\n",
              "      <td>0.932374</td>\n",
              "      <td>0.932444</td>\n",
              "      <td>0.933046</td>\n",
              "      <td>0.934319</td>\n",
              "      <td>0.932586</td>\n",
              "      <td>0.934602</td>\n",
              "      <td>0.932910</td>\n",
              "      <td>0.000835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>6.266607</td>\n",
              "      <td>0.029142</td>\n",
              "      <td>0.029243</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 5, 'n_est...</td>\n",
              "      <td>0.914704</td>\n",
              "      <td>0.914704</td>\n",
              "      <td>0.920115</td>\n",
              "      <td>0.924570</td>\n",
              "      <td>0.918816</td>\n",
              "      <td>0.915950</td>\n",
              "      <td>0.913403</td>\n",
              "      <td>0.905762</td>\n",
              "      <td>0.919771</td>\n",
              "      <td>0.912130</td>\n",
              "      <td>0.915993</td>\n",
              "      <td>0.004924</td>\n",
              "      <td>28</td>\n",
              "      <td>0.934069</td>\n",
              "      <td>0.933574</td>\n",
              "      <td>0.933326</td>\n",
              "      <td>0.933220</td>\n",
              "      <td>0.933046</td>\n",
              "      <td>0.934354</td>\n",
              "      <td>0.932798</td>\n",
              "      <td>0.934779</td>\n",
              "      <td>0.933541</td>\n",
              "      <td>0.934814</td>\n",
              "      <td>0.933752</td>\n",
              "      <td>0.000678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.776596</td>\n",
              "      <td>0.015448</td>\n",
              "      <td>0.017080</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.909930</td>\n",
              "      <td>0.911840</td>\n",
              "      <td>0.921706</td>\n",
              "      <td>0.920115</td>\n",
              "      <td>0.910856</td>\n",
              "      <td>0.908628</td>\n",
              "      <td>0.913085</td>\n",
              "      <td>0.902260</td>\n",
              "      <td>0.911493</td>\n",
              "      <td>0.907673</td>\n",
              "      <td>0.911759</td>\n",
              "      <td>0.005399</td>\n",
              "      <td>31</td>\n",
              "      <td>0.942770</td>\n",
              "      <td>0.942664</td>\n",
              "      <td>0.943654</td>\n",
              "      <td>0.942204</td>\n",
              "      <td>0.942100</td>\n",
              "      <td>0.941888</td>\n",
              "      <td>0.942065</td>\n",
              "      <td>0.943374</td>\n",
              "      <td>0.942065</td>\n",
              "      <td>0.941923</td>\n",
              "      <td>0.942471</td>\n",
              "      <td>0.000593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4.470422</td>\n",
              "      <td>0.020486</td>\n",
              "      <td>0.016756</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.912476</td>\n",
              "      <td>0.914386</td>\n",
              "      <td>0.915659</td>\n",
              "      <td>0.919160</td>\n",
              "      <td>0.912130</td>\n",
              "      <td>0.910856</td>\n",
              "      <td>0.911493</td>\n",
              "      <td>0.901305</td>\n",
              "      <td>0.916587</td>\n",
              "      <td>0.902897</td>\n",
              "      <td>0.911695</td>\n",
              "      <td>0.005380</td>\n",
              "      <td>32</td>\n",
              "      <td>0.947899</td>\n",
              "      <td>0.947793</td>\n",
              "      <td>0.946696</td>\n",
              "      <td>0.945989</td>\n",
              "      <td>0.947830</td>\n",
              "      <td>0.947370</td>\n",
              "      <td>0.947689</td>\n",
              "      <td>0.948608</td>\n",
              "      <td>0.947123</td>\n",
              "      <td>0.947972</td>\n",
              "      <td>0.947497</td>\n",
              "      <td>0.000702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>9.299419</td>\n",
              "      <td>0.039819</td>\n",
              "      <td>0.032180</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.914067</td>\n",
              "      <td>0.923934</td>\n",
              "      <td>0.929663</td>\n",
              "      <td>0.931254</td>\n",
              "      <td>0.921363</td>\n",
              "      <td>0.918816</td>\n",
              "      <td>0.918497</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.923910</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.921722</td>\n",
              "      <td>0.005206</td>\n",
              "      <td>19</td>\n",
              "      <td>0.959324</td>\n",
              "      <td>0.959324</td>\n",
              "      <td>0.959607</td>\n",
              "      <td>0.959288</td>\n",
              "      <td>0.958936</td>\n",
              "      <td>0.958193</td>\n",
              "      <td>0.957840</td>\n",
              "      <td>0.958971</td>\n",
              "      <td>0.959007</td>\n",
              "      <td>0.957840</td>\n",
              "      <td>0.958833</td>\n",
              "      <td>0.000611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>8.650103</td>\n",
              "      <td>0.048648</td>\n",
              "      <td>0.032106</td>\n",
              "      <td>0.001935</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.919796</td>\n",
              "      <td>0.922661</td>\n",
              "      <td>0.926162</td>\n",
              "      <td>0.929344</td>\n",
              "      <td>0.924865</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.921363</td>\n",
              "      <td>0.914995</td>\n",
              "      <td>0.925501</td>\n",
              "      <td>0.912448</td>\n",
              "      <td>0.921818</td>\n",
              "      <td>0.004882</td>\n",
              "      <td>18</td>\n",
              "      <td>0.964948</td>\n",
              "      <td>0.963745</td>\n",
              "      <td>0.964169</td>\n",
              "      <td>0.964877</td>\n",
              "      <td>0.964277</td>\n",
              "      <td>0.963640</td>\n",
              "      <td>0.965692</td>\n",
              "      <td>0.963110</td>\n",
              "      <td>0.964631</td>\n",
              "      <td>0.964878</td>\n",
              "      <td>0.964397</td>\n",
              "      <td>0.000722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>13.597590</td>\n",
              "      <td>0.026522</td>\n",
              "      <td>0.049054</td>\n",
              "      <td>0.001745</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.924252</td>\n",
              "      <td>0.925525</td>\n",
              "      <td>0.931891</td>\n",
              "      <td>0.933164</td>\n",
              "      <td>0.928685</td>\n",
              "      <td>0.926775</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.922318</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.924228</td>\n",
              "      <td>0.926497</td>\n",
              "      <td>0.003703</td>\n",
              "      <td>16</td>\n",
              "      <td>0.970961</td>\n",
              "      <td>0.970253</td>\n",
              "      <td>0.970218</td>\n",
              "      <td>0.970501</td>\n",
              "      <td>0.969335</td>\n",
              "      <td>0.969618</td>\n",
              "      <td>0.970219</td>\n",
              "      <td>0.970042</td>\n",
              "      <td>0.970219</td>\n",
              "      <td>0.970643</td>\n",
              "      <td>0.970201</td>\n",
              "      <td>0.000445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>12.416112</td>\n",
              "      <td>0.069828</td>\n",
              "      <td>0.047336</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.05</td>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
              "      <td>0.925525</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.933800</td>\n",
              "      <td>0.933800</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.926138</td>\n",
              "      <td>0.921044</td>\n",
              "      <td>0.929959</td>\n",
              "      <td>0.917861</td>\n",
              "      <td>0.926911</td>\n",
              "      <td>0.004724</td>\n",
              "      <td>15</td>\n",
              "      <td>0.973472</td>\n",
              "      <td>0.974179</td>\n",
              "      <td>0.972977</td>\n",
              "      <td>0.973366</td>\n",
              "      <td>0.973296</td>\n",
              "      <td>0.973897</td>\n",
              "      <td>0.973579</td>\n",
              "      <td>0.972412</td>\n",
              "      <td>0.974074</td>\n",
              "      <td>0.975277</td>\n",
              "      <td>0.973653</td>\n",
              "      <td>0.000735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>6.412038</td>\n",
              "      <td>0.020522</td>\n",
              "      <td>0.020894</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.918205</td>\n",
              "      <td>0.921706</td>\n",
              "      <td>0.929981</td>\n",
              "      <td>0.923297</td>\n",
              "      <td>0.919771</td>\n",
              "      <td>0.915632</td>\n",
              "      <td>0.917224</td>\n",
              "      <td>0.910856</td>\n",
              "      <td>0.921999</td>\n",
              "      <td>0.914995</td>\n",
              "      <td>0.919367</td>\n",
              "      <td>0.005021</td>\n",
              "      <td>25</td>\n",
              "      <td>0.964417</td>\n",
              "      <td>0.963462</td>\n",
              "      <td>0.965054</td>\n",
              "      <td>0.962932</td>\n",
              "      <td>0.963994</td>\n",
              "      <td>0.962685</td>\n",
              "      <td>0.963251</td>\n",
              "      <td>0.962650</td>\n",
              "      <td>0.964065</td>\n",
              "      <td>0.963180</td>\n",
              "      <td>0.963569</td>\n",
              "      <td>0.000751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>6.263932</td>\n",
              "      <td>0.030128</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.921069</td>\n",
              "      <td>0.922979</td>\n",
              "      <td>0.929663</td>\n",
              "      <td>0.923616</td>\n",
              "      <td>0.919771</td>\n",
              "      <td>0.922318</td>\n",
              "      <td>0.919771</td>\n",
              "      <td>0.909583</td>\n",
              "      <td>0.926457</td>\n",
              "      <td>0.912130</td>\n",
              "      <td>0.920736</td>\n",
              "      <td>0.005733</td>\n",
              "      <td>22</td>\n",
              "      <td>0.973720</td>\n",
              "      <td>0.973507</td>\n",
              "      <td>0.974462</td>\n",
              "      <td>0.973260</td>\n",
              "      <td>0.974393</td>\n",
              "      <td>0.973225</td>\n",
              "      <td>0.974074</td>\n",
              "      <td>0.973473</td>\n",
              "      <td>0.973331</td>\n",
              "      <td>0.974923</td>\n",
              "      <td>0.973837</td>\n",
              "      <td>0.000562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>12.395062</td>\n",
              "      <td>0.047547</td>\n",
              "      <td>0.040291</td>\n",
              "      <td>0.000623</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.925843</td>\n",
              "      <td>0.930936</td>\n",
              "      <td>0.932845</td>\n",
              "      <td>0.933482</td>\n",
              "      <td>0.933779</td>\n",
              "      <td>0.925501</td>\n",
              "      <td>0.925501</td>\n",
              "      <td>0.922318</td>\n",
              "      <td>0.929322</td>\n",
              "      <td>0.924228</td>\n",
              "      <td>0.928376</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>12</td>\n",
              "      <td>0.978919</td>\n",
              "      <td>0.978565</td>\n",
              "      <td>0.979202</td>\n",
              "      <td>0.978565</td>\n",
              "      <td>0.979380</td>\n",
              "      <td>0.977576</td>\n",
              "      <td>0.978000</td>\n",
              "      <td>0.976479</td>\n",
              "      <td>0.978319</td>\n",
              "      <td>0.979486</td>\n",
              "      <td>0.978449</td>\n",
              "      <td>0.000873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>12.065129</td>\n",
              "      <td>0.041969</td>\n",
              "      <td>0.040577</td>\n",
              "      <td>0.001232</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.924252</td>\n",
              "      <td>0.932845</td>\n",
              "      <td>0.936665</td>\n",
              "      <td>0.934437</td>\n",
              "      <td>0.928685</td>\n",
              "      <td>0.927412</td>\n",
              "      <td>0.926775</td>\n",
              "      <td>0.921363</td>\n",
              "      <td>0.930914</td>\n",
              "      <td>0.922636</td>\n",
              "      <td>0.928598</td>\n",
              "      <td>0.004838</td>\n",
              "      <td>11</td>\n",
              "      <td>0.986665</td>\n",
              "      <td>0.986665</td>\n",
              "      <td>0.986771</td>\n",
              "      <td>0.986099</td>\n",
              "      <td>0.986418</td>\n",
              "      <td>0.986312</td>\n",
              "      <td>0.987019</td>\n",
              "      <td>0.985145</td>\n",
              "      <td>0.986206</td>\n",
              "      <td>0.987338</td>\n",
              "      <td>0.986464</td>\n",
              "      <td>0.000567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>18.028583</td>\n",
              "      <td>0.083854</td>\n",
              "      <td>0.062051</td>\n",
              "      <td>0.001272</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.930936</td>\n",
              "      <td>0.933164</td>\n",
              "      <td>0.937301</td>\n",
              "      <td>0.936983</td>\n",
              "      <td>0.934734</td>\n",
              "      <td>0.932506</td>\n",
              "      <td>0.929640</td>\n",
              "      <td>0.927093</td>\n",
              "      <td>0.933461</td>\n",
              "      <td>0.930595</td>\n",
              "      <td>0.932641</td>\n",
              "      <td>0.003046</td>\n",
              "      <td>7</td>\n",
              "      <td>0.988257</td>\n",
              "      <td>0.989035</td>\n",
              "      <td>0.987443</td>\n",
              "      <td>0.988115</td>\n",
              "      <td>0.987974</td>\n",
              "      <td>0.988081</td>\n",
              "      <td>0.987833</td>\n",
              "      <td>0.987196</td>\n",
              "      <td>0.987868</td>\n",
              "      <td>0.988045</td>\n",
              "      <td>0.987985</td>\n",
              "      <td>0.000465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>17.163724</td>\n",
              "      <td>0.063067</td>\n",
              "      <td>0.062165</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>0.05</td>\n",
              "      <td>10</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>{'learning_rate': 0.05, 'max_depth': 10, 'n_es...</td>\n",
              "      <td>0.926798</td>\n",
              "      <td>0.935391</td>\n",
              "      <td>0.939847</td>\n",
              "      <td>0.936665</td>\n",
              "      <td>0.935053</td>\n",
              "      <td>0.931550</td>\n",
              "      <td>0.931232</td>\n",
              "      <td>0.926775</td>\n",
              "      <td>0.935371</td>\n",
              "      <td>0.926138</td>\n",
              "      <td>0.932482</td>\n",
              "      <td>0.004502</td>\n",
              "      <td>8</td>\n",
              "      <td>0.992077</td>\n",
              "      <td>0.993138</td>\n",
              "      <td>0.992077</td>\n",
              "      <td>0.991653</td>\n",
              "      <td>0.992396</td>\n",
              "      <td>0.991582</td>\n",
              "      <td>0.992537</td>\n",
              "      <td>0.991688</td>\n",
              "      <td>0.991724</td>\n",
              "      <td>0.992608</td>\n",
              "      <td>0.992148</td>\n",
              "      <td>0.000487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "0        2.587727      0.049830  ...          0.923240         0.000858\n",
              "1        2.222049      0.018294  ...          0.924266         0.000658\n",
              "2        4.961192      0.020051  ...          0.937862         0.000849\n",
              "3        4.270570      0.033783  ...          0.939132         0.000719\n",
              "4        7.240818      0.021867  ...          0.946991         0.000573\n",
              "5        6.139449      0.024851  ...          0.947490         0.000486\n",
              "6        4.769385      0.018682  ...          0.957765         0.000713\n",
              "7        4.437964      0.029723  ...          0.963873         0.000550\n",
              "8        9.079178      0.053835  ...          0.978212         0.000625\n",
              "9        8.168818      0.082902  ...          0.980745         0.001164\n",
              "10      13.357159      0.058490  ...          0.990588         0.000541\n",
              "11      11.764528      0.078668  ...          0.989934         0.000649\n",
              "12       6.310281      0.026760  ...          0.978110         0.000781\n",
              "13       6.123533      0.026038  ...          0.986471         0.000573\n",
              "14      11.945802      0.048568  ...          0.993573         0.000310\n",
              "15      11.186296      0.086230  ...          0.995890         0.000304\n",
              "16      17.481073      0.055557  ...          0.998734         0.000144\n",
              "17      16.145331      0.187300  ...          0.999204         0.000188\n",
              "18       2.484758      0.015362  ...          0.876046         0.001214\n",
              "19       2.142451      0.009055  ...          0.874939         0.001583\n",
              "20       4.942250      0.014930  ...          0.884988         0.001161\n",
              "21       4.279927      0.019234  ...          0.885203         0.000833\n",
              "22       7.401674      0.017359  ...          0.893338         0.000740\n",
              "23       6.404302      0.019687  ...          0.893487         0.000973\n",
              "24       4.731992      0.022676  ...          0.921284         0.000763\n",
              "25       4.404850      0.020044  ...          0.921482         0.000765\n",
              "26       9.459752      0.030713  ...          0.927690         0.000654\n",
              "27       8.791057      0.049795  ...          0.930459         0.000819\n",
              "28      14.222011      0.034034  ...          0.934039         0.000446\n",
              "29      13.294674      0.047534  ...          0.936723         0.000732\n",
              "30       6.363148      0.024638  ...          0.942683         0.000927\n",
              "31       6.169450      0.034134  ...          0.948735         0.000751\n",
              "32      12.768636      0.047449  ...          0.949474         0.000424\n",
              "33      12.396803      0.083756  ...          0.957885         0.000523\n",
              "34      19.062381      0.067844  ...          0.955508         0.000504\n",
              "35      18.532152      0.098824  ...          0.964482         0.000835\n",
              "36       2.495075      0.010015  ...          0.905658         0.001004\n",
              "37       2.163268      0.009458  ...          0.906107         0.000898\n",
              "38       4.937597      0.013156  ...          0.923810         0.000918\n",
              "39       4.244409      0.014426  ...          0.925086         0.000519\n",
              "40       7.315270      0.021860  ...          0.932910         0.000835\n",
              "41       6.266607      0.029142  ...          0.933752         0.000678\n",
              "42       4.776596      0.015448  ...          0.942471         0.000593\n",
              "43       4.470422      0.020486  ...          0.947497         0.000702\n",
              "44       9.299419      0.039819  ...          0.958833         0.000611\n",
              "45       8.650103      0.048648  ...          0.964397         0.000722\n",
              "46      13.597590      0.026522  ...          0.970201         0.000445\n",
              "47      12.416112      0.069828  ...          0.973653         0.000735\n",
              "48       6.412038      0.020522  ...          0.963569         0.000751\n",
              "49       6.263932      0.030128  ...          0.973837         0.000562\n",
              "50      12.395062      0.047547  ...          0.978449         0.000873\n",
              "51      12.065129      0.041969  ...          0.986464         0.000567\n",
              "52      18.028583      0.083854  ...          0.987985         0.000465\n",
              "53      17.163724      0.063067  ...          0.992148         0.000487\n",
              "\n",
              "[54 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJkMK9Jy72YF",
        "outputId": "bd2f6659-87c3-449a-8e82-7fb8ffb59ced"
      },
      "source": [
        "model_cv.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 150, 'subsample': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLYztp9-zjLa",
        "outputId": "fc0a1b7a-d292-4169-c29e-1a504b402c2e"
      },
      "source": [
        "# chosen hyperparameters\n",
        "\n",
        "params = {'learning_rate': 0.1,\n",
        "           'max_depth': 10,\n",
        "          'subsample':1,\n",
        "          'n_estimators': 150\n",
        "         }\n",
        "\n",
        "# fit model on training data\n",
        "model = XGBClassifier(params = params)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic',\n",
              "              params={'learning_rate': 0.1, 'max_depth': 10,\n",
              "                      'n_estimators': 150, 'subsample': 1},\n",
              "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn7w7IXj9CsE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbybbeC49MpG"
      },
      "source": [
        "predicted = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5RF_xMB9MpG",
        "outputId": "44638587-1f46-4b8b-ad7a-49ac71310dce"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6327  730]\n",
            " [ 569 5838]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "983GrSFM9MpH",
        "outputId": "de88c006-7f2d-4d37-dce5-05e3d52d456d"
      },
      "source": [
        "print(metrics.classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      7057\n",
            "           1       0.89      0.91      0.90      6407\n",
            "\n",
            "    accuracy                           0.90     13464\n",
            "   macro avg       0.90      0.90      0.90     13464\n",
            "weighted avg       0.90      0.90      0.90     13464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvSOFuF29MpH",
        "outputId": "2a87b79a-a617-403a-a680-580aed686e3a"
      },
      "source": [
        "print(model.score(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9035204991087344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9fwpNA9OnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}