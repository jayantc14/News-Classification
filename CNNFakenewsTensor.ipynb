{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNFakenewsTensor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SSu7Vcjfc9YI_sFXEasqD9P7RH1MdTIZ",
      "authorship_tag": "ABX9TyMSMABulD2V6Mi92daMt/H3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayantc14/News-Classification/blob/main/CNNFakenewsTensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5YqMRj-p5tl"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "import gc # for deleting unused variables\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru8ano75i-R_",
        "outputId": "eb0c67ce-930b-471d-9565-27badacd53a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMtAnEiiq97H"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/IIM/data\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yvkB4QZron2"
      },
      "source": [
        "df.drop(['Unnamed: 0'],axis = 1,inplace  = True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QWxCRfSfrpzu",
        "outputId": "5d31eab0-d799-4241-d946-5fce869df8b6"
      },
      "source": [
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>Sixltr</th>\n",
              "      <th>number</th>\n",
              "      <th>quant</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>tentat</th>\n",
              "      <th>certain</th>\n",
              "      <th>achieve</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focuspast</th>\n",
              "      <th>focuspresent</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>FREScore</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97.02</td>\n",
              "      <td>22.27</td>\n",
              "      <td>35.07</td>\n",
              "      <td>23.41</td>\n",
              "      <td>28.44</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1.34</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.20</td>\n",
              "      <td>5.87</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.93</td>\n",
              "      <td>4.01</td>\n",
              "      <td>6.81</td>\n",
              "      <td>2.00</td>\n",
              "      <td>42.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96.86</td>\n",
              "      <td>13.98</td>\n",
              "      <td>49.52</td>\n",
              "      <td>20.23</td>\n",
              "      <td>32.85</td>\n",
              "      <td>2.39</td>\n",
              "      <td>1.28</td>\n",
              "      <td>2.71</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.96</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.12</td>\n",
              "      <td>3.83</td>\n",
              "      <td>5.10</td>\n",
              "      <td>2.07</td>\n",
              "      <td>32.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94.73</td>\n",
              "      <td>16.26</td>\n",
              "      <td>29.43</td>\n",
              "      <td>24.05</td>\n",
              "      <td>27.35</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.88</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>6.13</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.47</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.97</td>\n",
              "      <td>39.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96.40</td>\n",
              "      <td>12.12</td>\n",
              "      <td>55.62</td>\n",
              "      <td>22.29</td>\n",
              "      <td>32.19</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.32</td>\n",
              "      <td>6.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.33</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.53</td>\n",
              "      <td>45.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96.29</td>\n",
              "      <td>22.73</td>\n",
              "      <td>15.88</td>\n",
              "      <td>22.05</td>\n",
              "      <td>27.21</td>\n",
              "      <td>4.19</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.86</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.81</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.93</td>\n",
              "      <td>3.49</td>\n",
              "      <td>5.47</td>\n",
              "      <td>0.23</td>\n",
              "      <td>50.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44873</th>\n",
              "      <td>96.34</td>\n",
              "      <td>16.74</td>\n",
              "      <td>46.26</td>\n",
              "      <td>49.00</td>\n",
              "      <td>28.01</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2.04</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.78</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.37</td>\n",
              "      <td>5.19</td>\n",
              "      <td>3.71</td>\n",
              "      <td>0.37</td>\n",
              "      <td>22.35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44874</th>\n",
              "      <td>94.03</td>\n",
              "      <td>14.89</td>\n",
              "      <td>56.75</td>\n",
              "      <td>27.73</td>\n",
              "      <td>19.02</td>\n",
              "      <td>3.28</td>\n",
              "      <td>1.97</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.30</td>\n",
              "      <td>5.57</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.93</td>\n",
              "      <td>6.23</td>\n",
              "      <td>0.98</td>\n",
              "      <td>51.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44875</th>\n",
              "      <td>90.88</td>\n",
              "      <td>33.24</td>\n",
              "      <td>22.15</td>\n",
              "      <td>38.88</td>\n",
              "      <td>22.66</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.99</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.71</td>\n",
              "      <td>2.22</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.68</td>\n",
              "      <td>4.68</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.03</td>\n",
              "      <td>2.83</td>\n",
              "      <td>5.94</td>\n",
              "      <td>1.52</td>\n",
              "      <td>28.24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44876</th>\n",
              "      <td>91.99</td>\n",
              "      <td>25.14</td>\n",
              "      <td>49.16</td>\n",
              "      <td>47.70</td>\n",
              "      <td>20.34</td>\n",
              "      <td>4.40</td>\n",
              "      <td>2.31</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1.26</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2.10</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.77</td>\n",
              "      <td>7.13</td>\n",
              "      <td>0.84</td>\n",
              "      <td>27.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44877</th>\n",
              "      <td>95.49</td>\n",
              "      <td>21.45</td>\n",
              "      <td>10.28</td>\n",
              "      <td>35.68</td>\n",
              "      <td>23.54</td>\n",
              "      <td>1.23</td>\n",
              "      <td>1.35</td>\n",
              "      <td>1.01</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.23</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.79</td>\n",
              "      <td>4.48</td>\n",
              "      <td>6.61</td>\n",
              "      <td>1.46</td>\n",
              "      <td>48.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44878 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Analytic  Authentic   Tone  ...  focusfuture  FREScore  target\n",
              "0         97.02      22.27  35.07  ...         2.00     42.04       1\n",
              "1         96.86      13.98  49.52  ...         2.07     32.57       1\n",
              "2         94.73      16.26  29.43  ...         1.97     39.91       1\n",
              "3         96.40      12.12  55.62  ...         0.53     45.49       1\n",
              "4         96.29      22.73  15.88  ...         0.23     50.80       1\n",
              "...         ...        ...    ...  ...          ...       ...     ...\n",
              "44873     96.34      16.74  46.26  ...         0.37     22.35       0\n",
              "44874     94.03      14.89  56.75  ...         0.98     51.41       0\n",
              "44875     90.88      33.24  22.15  ...         1.52     28.24       0\n",
              "44876     91.99      25.14  49.16  ...         0.84     27.16       0\n",
              "44877     95.49      21.45  10.28  ...         1.46     48.88       0\n",
              "\n",
              "[44878 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6BMAzqr7HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24a19c2-0657-4e35-d6bd-3e3fd6ef8db5"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28721 train examples\n",
            "7181 validation examples\n",
            "8976 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996DerhILYBH"
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVWIDBlLYHqC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlZsAm3IYH3-"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCPKp6yLYC6"
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjIBZEpLYHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735f76e8-264d-4f30-a85e-181f82b746fd"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  \n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']\n",
            "A batch of targets: tf.Tensor([1 1 0 0 1], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0af_RDSnLYJK"
      },
      "source": [
        "# We will use this batch to demonstrate several types of feature columns\n",
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_brV78bqLYMS"
      },
      "source": [
        "# A utility method to create a feature column\n",
        "# and to transform a batch of data\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm_Zw8fCLYN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effec861-81de-4d0d-9ac1-feda7d960d43"
      },
      "source": [
        "photo_count = feature_column.numeric_column('quant')\n",
        "demo(photo_count)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.58]\n",
            " [1.63]\n",
            " [2.15]\n",
            " [4.46]\n",
            " [0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-NKfHMLYSH"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs_xrFZzLYUe"
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoFfxHYjLYXv"
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONnCnqa0Ry8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e7a8bb-f6f3-46ce-9d54-83bfaf840faf"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(.1),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=30)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "884/898 [============================>.] - ETA: 0s - loss: 0.4112 - accuracy: 0.8359WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "898/898 [==============================] - 5s 4ms/step - loss: 0.4098 - accuracy: 0.8363 - val_loss: 0.3108 - val_accuracy: 0.8848\n",
            "Epoch 2/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2910 - accuracy: 0.8766 - val_loss: 0.2730 - val_accuracy: 0.8889\n",
            "Epoch 3/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2740 - accuracy: 0.8835 - val_loss: 0.2653 - val_accuracy: 0.8921\n",
            "Epoch 4/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2666 - accuracy: 0.8867 - val_loss: 0.2594 - val_accuracy: 0.8935\n",
            "Epoch 5/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2629 - accuracy: 0.8891 - val_loss: 0.2515 - val_accuracy: 0.8958\n",
            "Epoch 6/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2588 - accuracy: 0.8916 - val_loss: 0.2645 - val_accuracy: 0.8965\n",
            "Epoch 7/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2564 - accuracy: 0.8922 - val_loss: 0.2603 - val_accuracy: 0.8990\n",
            "Epoch 8/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2508 - accuracy: 0.8954 - val_loss: 0.2484 - val_accuracy: 0.9008\n",
            "Epoch 9/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2500 - accuracy: 0.8960 - val_loss: 0.2607 - val_accuracy: 0.8776\n",
            "Epoch 10/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2444 - accuracy: 0.8971 - val_loss: 0.2456 - val_accuracy: 0.9031\n",
            "Epoch 11/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2420 - accuracy: 0.8979 - val_loss: 0.2576 - val_accuracy: 0.9036\n",
            "Epoch 12/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2400 - accuracy: 0.8990 - val_loss: 0.2428 - val_accuracy: 0.9056\n",
            "Epoch 13/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2390 - accuracy: 0.9008 - val_loss: 0.2396 - val_accuracy: 0.9034\n",
            "Epoch 14/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2343 - accuracy: 0.9010 - val_loss: 0.2457 - val_accuracy: 0.8915\n",
            "Epoch 15/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2331 - accuracy: 0.9020 - val_loss: 0.2372 - val_accuracy: 0.9086\n",
            "Epoch 16/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2303 - accuracy: 0.9054 - val_loss: 0.2370 - val_accuracy: 0.9038\n",
            "Epoch 17/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2271 - accuracy: 0.9052 - val_loss: 0.2378 - val_accuracy: 0.9060\n",
            "Epoch 18/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2266 - accuracy: 0.9047 - val_loss: 0.2454 - val_accuracy: 0.8932\n",
            "Epoch 19/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2299 - accuracy: 0.9056 - val_loss: 0.2617 - val_accuracy: 0.9064\n",
            "Epoch 20/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2232 - accuracy: 0.9064 - val_loss: 0.2439 - val_accuracy: 0.9046\n",
            "Epoch 21/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2230 - accuracy: 0.9067 - val_loss: 0.2355 - val_accuracy: 0.9031\n",
            "Epoch 22/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2191 - accuracy: 0.9080 - val_loss: 0.2569 - val_accuracy: 0.9060\n",
            "Epoch 23/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2187 - accuracy: 0.9062 - val_loss: 0.2342 - val_accuracy: 0.9085\n",
            "Epoch 24/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2171 - accuracy: 0.9104 - val_loss: 0.2403 - val_accuracy: 0.9099\n",
            "Epoch 25/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2154 - accuracy: 0.9104 - val_loss: 0.2356 - val_accuracy: 0.9095\n",
            "Epoch 26/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2127 - accuracy: 0.9107 - val_loss: 0.2387 - val_accuracy: 0.9117\n",
            "Epoch 27/30\n",
            "898/898 [==============================] - 3s 3ms/step - loss: 0.2132 - accuracy: 0.9110 - val_loss: 0.2417 - val_accuracy: 0.9116\n",
            "Epoch 28/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2113 - accuracy: 0.9106 - val_loss: 0.2320 - val_accuracy: 0.9038\n",
            "Epoch 29/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2115 - accuracy: 0.9113 - val_loss: 0.2355 - val_accuracy: 0.9117\n",
            "Epoch 30/30\n",
            "898/898 [==============================] - 3s 4ms/step - loss: 0.2089 - accuracy: 0.9126 - val_loss: 0.2322 - val_accuracy: 0.9135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f21115a7e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgG_OvFaRy-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a632ff8f-8f36-4c2c-d656-965216e35d95"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9064\n",
            "Accuracy 0.9064171314239502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3euXS38oRzDV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEF8ts_NuElq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWq_Pk8jzZk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbsf8uil-7e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvnOx5-Yl-9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLWDkgdzl_B2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9fwpNA9OnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}