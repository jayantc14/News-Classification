{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNFakenewsTensor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SSu7Vcjfc9YI_sFXEasqD9P7RH1MdTIZ",
      "authorship_tag": "ABX9TyPhZ4wzpJSWIOlV8yImH4Sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayantc14/News-Classification/blob/main/CNNFakenewsTensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5YqMRj-p5tl"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "import gc # for deleting unused variables\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru8ano75i-R_",
        "outputId": "1a9f64f7-3696-482c-f4c4-2feede6ff2ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMtAnEiiq97H"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/IIM/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yvkB4QZron2"
      },
      "source": [
        "df.drop(['Unnamed: 0'],axis = 1,inplace  = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QWxCRfSfrpzu",
        "outputId": "1818c273-cbf4-4b41-d740-f117bac2a828"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>Sixltr</th>\n",
              "      <th>number</th>\n",
              "      <th>quant</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>tentat</th>\n",
              "      <th>certain</th>\n",
              "      <th>achieve</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focuspast</th>\n",
              "      <th>focuspresent</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>FREScore</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97.02</td>\n",
              "      <td>22.27</td>\n",
              "      <td>35.07</td>\n",
              "      <td>23.41</td>\n",
              "      <td>28.44</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1.34</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1.20</td>\n",
              "      <td>5.87</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.93</td>\n",
              "      <td>4.01</td>\n",
              "      <td>6.81</td>\n",
              "      <td>2.00</td>\n",
              "      <td>42.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96.86</td>\n",
              "      <td>13.98</td>\n",
              "      <td>49.52</td>\n",
              "      <td>20.23</td>\n",
              "      <td>32.85</td>\n",
              "      <td>2.39</td>\n",
              "      <td>1.28</td>\n",
              "      <td>2.71</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.96</td>\n",
              "      <td>8.61</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.12</td>\n",
              "      <td>3.83</td>\n",
              "      <td>5.10</td>\n",
              "      <td>2.07</td>\n",
              "      <td>32.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94.73</td>\n",
              "      <td>16.26</td>\n",
              "      <td>29.43</td>\n",
              "      <td>24.05</td>\n",
              "      <td>27.35</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.88</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>6.13</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.47</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.97</td>\n",
              "      <td>39.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96.40</td>\n",
              "      <td>12.12</td>\n",
              "      <td>55.62</td>\n",
              "      <td>22.29</td>\n",
              "      <td>32.19</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2.11</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.32</td>\n",
              "      <td>6.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.33</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.53</td>\n",
              "      <td>45.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>96.29</td>\n",
              "      <td>22.73</td>\n",
              "      <td>15.88</td>\n",
              "      <td>22.05</td>\n",
              "      <td>27.21</td>\n",
              "      <td>4.19</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.86</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.81</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.93</td>\n",
              "      <td>3.49</td>\n",
              "      <td>5.47</td>\n",
              "      <td>0.23</td>\n",
              "      <td>50.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44873</th>\n",
              "      <td>96.34</td>\n",
              "      <td>16.74</td>\n",
              "      <td>46.26</td>\n",
              "      <td>49.00</td>\n",
              "      <td>28.01</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2.04</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.78</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.37</td>\n",
              "      <td>5.19</td>\n",
              "      <td>3.71</td>\n",
              "      <td>0.37</td>\n",
              "      <td>22.35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44874</th>\n",
              "      <td>94.03</td>\n",
              "      <td>14.89</td>\n",
              "      <td>56.75</td>\n",
              "      <td>27.73</td>\n",
              "      <td>19.02</td>\n",
              "      <td>3.28</td>\n",
              "      <td>1.97</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.31</td>\n",
              "      <td>1.97</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.30</td>\n",
              "      <td>5.57</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.93</td>\n",
              "      <td>6.23</td>\n",
              "      <td>0.98</td>\n",
              "      <td>51.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44875</th>\n",
              "      <td>90.88</td>\n",
              "      <td>33.24</td>\n",
              "      <td>22.15</td>\n",
              "      <td>38.88</td>\n",
              "      <td>22.66</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.99</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.71</td>\n",
              "      <td>2.22</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.68</td>\n",
              "      <td>4.68</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.03</td>\n",
              "      <td>2.83</td>\n",
              "      <td>5.94</td>\n",
              "      <td>1.52</td>\n",
              "      <td>28.24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44876</th>\n",
              "      <td>91.99</td>\n",
              "      <td>25.14</td>\n",
              "      <td>49.16</td>\n",
              "      <td>47.70</td>\n",
              "      <td>20.34</td>\n",
              "      <td>4.40</td>\n",
              "      <td>2.31</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1.26</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2.10</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.14</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.77</td>\n",
              "      <td>7.13</td>\n",
              "      <td>0.84</td>\n",
              "      <td>27.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44877</th>\n",
              "      <td>95.49</td>\n",
              "      <td>21.45</td>\n",
              "      <td>10.28</td>\n",
              "      <td>35.68</td>\n",
              "      <td>23.54</td>\n",
              "      <td>1.23</td>\n",
              "      <td>1.35</td>\n",
              "      <td>1.01</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.23</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.79</td>\n",
              "      <td>4.48</td>\n",
              "      <td>6.61</td>\n",
              "      <td>1.46</td>\n",
              "      <td>48.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44878 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Analytic  Authentic   Tone  ...  focusfuture  FREScore  target\n",
              "0         97.02      22.27  35.07  ...         2.00     42.04       1\n",
              "1         96.86      13.98  49.52  ...         2.07     32.57       1\n",
              "2         94.73      16.26  29.43  ...         1.97     39.91       1\n",
              "3         96.40      12.12  55.62  ...         0.53     45.49       1\n",
              "4         96.29      22.73  15.88  ...         0.23     50.80       1\n",
              "...         ...        ...    ...  ...          ...       ...     ...\n",
              "44873     96.34      16.74  46.26  ...         0.37     22.35       0\n",
              "44874     94.03      14.89  56.75  ...         0.98     51.41       0\n",
              "44875     90.88      33.24  22.15  ...         1.52     28.24       0\n",
              "44876     91.99      25.14  49.16  ...         0.84     27.16       0\n",
              "44877     95.49      21.45  10.28  ...         1.46     48.88       0\n",
              "\n",
              "[44878 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6BMAzqr7HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982d1295-52a2-4f4e-a007-27feaf520b31"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28721 train examples\n",
            "7181 validation examples\n",
            "8976 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996DerhILYBH"
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVWIDBlLYHqC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlZsAm3IYH3-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCPKp6yLYC6"
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjIBZEpLYHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8866c398-e883-404e-b28e-95338186c5c9"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  \n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']\n",
            "A batch of targets: tf.Tensor([0 0 1 1 0], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0af_RDSnLYJK"
      },
      "source": [
        "# We will use this batch to demonstrate several types of feature columns\n",
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_brV78bqLYMS"
      },
      "source": [
        "# A utility method to create a feature column\n",
        "# and to transform a batch of data\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm_Zw8fCLYN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d293c10e-c8c5-4de1-9cc9-0b0e56c3aee2"
      },
      "source": [
        "photo_count = feature_column.numeric_column('quant')\n",
        "demo(photo_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.11]\n",
            " [1.29]\n",
            " [2.22]\n",
            " [2.24]\n",
            " [0.83]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7-NKfHMLYSH"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['Analytic', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'number', 'quant', 'posemo', 'negemo', 'tentat', 'certain', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'FREScore']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs_xrFZzLYUe"
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoFfxHYjLYXv"
      },
      "source": [
        "batch_size = 50\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONnCnqa0Ry8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c14b288-0d23-4177-bf92-05ba98b1d6ee"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  \n",
        "  layers.Dropout(.1),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "563/575 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.8293WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Analytic': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'Authentic': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'Tone': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>, 'WPS': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'Sixltr': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float64>, 'number': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=float64>, 'quant': <tf.Tensor 'ExpandDims_15:0' shape=(None, 1) dtype=float64>, 'posemo': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'negemo': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'tentat': <tf.Tensor 'ExpandDims_18:0' shape=(None, 1) dtype=float64>, 'certain': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'achieve': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'power': <tf.Tensor 'ExpandDims_14:0' shape=(None, 1) dtype=float64>, 'reward': <tf.Tensor 'ExpandDims_16:0' shape=(None, 1) dtype=float64>, 'risk': <tf.Tensor 'ExpandDims_17:0' shape=(None, 1) dtype=float64>, 'focuspast': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'focuspresent': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'focusfuture': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'FREScore': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.4533 - accuracy: 0.8303 - val_loss: 0.3146 - val_accuracy: 0.8854\n",
            "Epoch 2/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.8782 - val_loss: 0.2743 - val_accuracy: 0.8940\n",
            "Epoch 3/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2737 - accuracy: 0.8841 - val_loss: 0.2570 - val_accuracy: 0.8901\n",
            "Epoch 4/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2702 - accuracy: 0.8875 - val_loss: 0.2564 - val_accuracy: 0.8999\n",
            "Epoch 5/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2627 - accuracy: 0.8918 - val_loss: 0.2480 - val_accuracy: 0.9006\n",
            "Epoch 6/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2586 - accuracy: 0.8923 - val_loss: 0.2523 - val_accuracy: 0.8912\n",
            "Epoch 7/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2564 - accuracy: 0.8930 - val_loss: 0.2409 - val_accuracy: 0.9000\n",
            "Epoch 8/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2523 - accuracy: 0.8953 - val_loss: 0.2413 - val_accuracy: 0.8986\n",
            "Epoch 9/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2505 - accuracy: 0.8968 - val_loss: 0.2457 - val_accuracy: 0.8931\n",
            "Epoch 10/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2461 - accuracy: 0.8987 - val_loss: 0.2343 - val_accuracy: 0.9038\n",
            "Epoch 11/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2415 - accuracy: 0.8994 - val_loss: 0.2427 - val_accuracy: 0.9078\n",
            "Epoch 12/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2408 - accuracy: 0.8996 - val_loss: 0.2376 - val_accuracy: 0.9067\n",
            "Epoch 13/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2390 - accuracy: 0.9004 - val_loss: 0.2330 - val_accuracy: 0.8979\n",
            "Epoch 14/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2366 - accuracy: 0.9028 - val_loss: 0.2653 - val_accuracy: 0.8979\n",
            "Epoch 15/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2332 - accuracy: 0.9047 - val_loss: 0.2272 - val_accuracy: 0.9125\n",
            "Epoch 16/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2333 - accuracy: 0.9043 - val_loss: 0.2222 - val_accuracy: 0.9034\n",
            "Epoch 17/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2299 - accuracy: 0.9051 - val_loss: 0.2236 - val_accuracy: 0.9080\n",
            "Epoch 18/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2290 - accuracy: 0.9050 - val_loss: 0.2324 - val_accuracy: 0.9088\n",
            "Epoch 19/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2262 - accuracy: 0.9051 - val_loss: 0.2252 - val_accuracy: 0.9092\n",
            "Epoch 20/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2269 - accuracy: 0.9041 - val_loss: 0.2226 - val_accuracy: 0.9120\n",
            "Epoch 21/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2246 - accuracy: 0.9076 - val_loss: 0.2551 - val_accuracy: 0.9029\n",
            "Epoch 22/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2204 - accuracy: 0.9079 - val_loss: 0.2263 - val_accuracy: 0.9078\n",
            "Epoch 23/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2198 - accuracy: 0.9085 - val_loss: 0.2177 - val_accuracy: 0.9077\n",
            "Epoch 24/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2183 - accuracy: 0.9099 - val_loss: 0.2209 - val_accuracy: 0.9093\n",
            "Epoch 25/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2166 - accuracy: 0.9092 - val_loss: 0.2317 - val_accuracy: 0.8918\n",
            "Epoch 26/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2158 - accuracy: 0.9116 - val_loss: 0.2320 - val_accuracy: 0.8960\n",
            "Epoch 27/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2151 - accuracy: 0.9101 - val_loss: 0.2249 - val_accuracy: 0.9070\n",
            "Epoch 28/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2118 - accuracy: 0.9126 - val_loss: 0.2235 - val_accuracy: 0.9095\n",
            "Epoch 29/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2131 - accuracy: 0.9113 - val_loss: 0.2244 - val_accuracy: 0.9081\n",
            "Epoch 30/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2102 - accuracy: 0.9126 - val_loss: 0.2210 - val_accuracy: 0.9068\n",
            "Epoch 31/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2101 - accuracy: 0.9115 - val_loss: 0.2209 - val_accuracy: 0.9025\n",
            "Epoch 32/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2069 - accuracy: 0.9139 - val_loss: 0.2185 - val_accuracy: 0.9137\n",
            "Epoch 33/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2085 - accuracy: 0.9131 - val_loss: 0.2201 - val_accuracy: 0.9110\n",
            "Epoch 34/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2077 - accuracy: 0.9146 - val_loss: 0.2202 - val_accuracy: 0.9138\n",
            "Epoch 35/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2026 - accuracy: 0.9150 - val_loss: 0.2236 - val_accuracy: 0.9128\n",
            "Epoch 36/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2019 - accuracy: 0.9165 - val_loss: 0.2148 - val_accuracy: 0.9142\n",
            "Epoch 37/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.2005 - accuracy: 0.9164 - val_loss: 0.2341 - val_accuracy: 0.8993\n",
            "Epoch 38/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.2012 - accuracy: 0.9160 - val_loss: 0.2130 - val_accuracy: 0.9116\n",
            "Epoch 39/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1996 - accuracy: 0.9150 - val_loss: 0.2219 - val_accuracy: 0.9074\n",
            "Epoch 40/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1964 - accuracy: 0.9178 - val_loss: 0.2233 - val_accuracy: 0.9099\n",
            "Epoch 41/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1955 - accuracy: 0.9189 - val_loss: 0.2192 - val_accuracy: 0.9099\n",
            "Epoch 42/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1944 - accuracy: 0.9180 - val_loss: 0.2205 - val_accuracy: 0.9125\n",
            "Epoch 43/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1932 - accuracy: 0.9180 - val_loss: 0.2235 - val_accuracy: 0.8999\n",
            "Epoch 44/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1941 - accuracy: 0.9189 - val_loss: 0.2222 - val_accuracy: 0.9134\n",
            "Epoch 45/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1926 - accuracy: 0.9190 - val_loss: 0.2300 - val_accuracy: 0.9052\n",
            "Epoch 46/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1940 - accuracy: 0.9192 - val_loss: 0.2245 - val_accuracy: 0.9151\n",
            "Epoch 47/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1879 - accuracy: 0.9223 - val_loss: 0.2241 - val_accuracy: 0.9145\n",
            "Epoch 48/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1864 - accuracy: 0.9213 - val_loss: 0.2285 - val_accuracy: 0.9028\n",
            "Epoch 49/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1869 - accuracy: 0.9223 - val_loss: 0.2190 - val_accuracy: 0.9121\n",
            "Epoch 50/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1867 - accuracy: 0.9220 - val_loss: 0.2191 - val_accuracy: 0.9105\n",
            "Epoch 51/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1829 - accuracy: 0.9223 - val_loss: 0.2258 - val_accuracy: 0.9141\n",
            "Epoch 52/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1810 - accuracy: 0.9226 - val_loss: 0.2272 - val_accuracy: 0.9089\n",
            "Epoch 53/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1812 - accuracy: 0.9240 - val_loss: 0.2225 - val_accuracy: 0.9135\n",
            "Epoch 54/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1803 - accuracy: 0.9240 - val_loss: 0.2256 - val_accuracy: 0.9157\n",
            "Epoch 55/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1783 - accuracy: 0.9248 - val_loss: 0.2221 - val_accuracy: 0.9139\n",
            "Epoch 56/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1778 - accuracy: 0.9243 - val_loss: 0.2266 - val_accuracy: 0.9102\n",
            "Epoch 57/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1785 - accuracy: 0.9256 - val_loss: 0.2340 - val_accuracy: 0.9164\n",
            "Epoch 58/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1741 - accuracy: 0.9263 - val_loss: 0.2202 - val_accuracy: 0.9121\n",
            "Epoch 59/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1759 - accuracy: 0.9253 - val_loss: 0.2271 - val_accuracy: 0.9135\n",
            "Epoch 60/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1719 - accuracy: 0.9263 - val_loss: 0.2300 - val_accuracy: 0.9131\n",
            "Epoch 61/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1699 - accuracy: 0.9286 - val_loss: 0.2379 - val_accuracy: 0.9142\n",
            "Epoch 62/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1703 - accuracy: 0.9281 - val_loss: 0.2340 - val_accuracy: 0.9112\n",
            "Epoch 63/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1712 - accuracy: 0.9294 - val_loss: 0.2305 - val_accuracy: 0.9054\n",
            "Epoch 64/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1681 - accuracy: 0.9289 - val_loss: 0.2250 - val_accuracy: 0.9114\n",
            "Epoch 65/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1668 - accuracy: 0.9296 - val_loss: 0.2308 - val_accuracy: 0.9152\n",
            "Epoch 66/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1699 - accuracy: 0.9297 - val_loss: 0.2362 - val_accuracy: 0.9105\n",
            "Epoch 67/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1701 - accuracy: 0.9299 - val_loss: 0.2346 - val_accuracy: 0.9073\n",
            "Epoch 68/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1662 - accuracy: 0.9301 - val_loss: 0.2312 - val_accuracy: 0.9138\n",
            "Epoch 69/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1627 - accuracy: 0.9308 - val_loss: 0.2301 - val_accuracy: 0.9119\n",
            "Epoch 70/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1617 - accuracy: 0.9325 - val_loss: 0.2252 - val_accuracy: 0.9071\n",
            "Epoch 71/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1596 - accuracy: 0.9319 - val_loss: 0.2267 - val_accuracy: 0.9166\n",
            "Epoch 72/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1605 - accuracy: 0.9315 - val_loss: 0.2490 - val_accuracy: 0.9156\n",
            "Epoch 73/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1568 - accuracy: 0.9340 - val_loss: 0.2408 - val_accuracy: 0.9155\n",
            "Epoch 74/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1591 - accuracy: 0.9317 - val_loss: 0.2420 - val_accuracy: 0.9184\n",
            "Epoch 75/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1556 - accuracy: 0.9347 - val_loss: 0.2442 - val_accuracy: 0.9093\n",
            "Epoch 76/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1559 - accuracy: 0.9333 - val_loss: 0.2419 - val_accuracy: 0.9141\n",
            "Epoch 77/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1566 - accuracy: 0.9343 - val_loss: 0.2588 - val_accuracy: 0.8985\n",
            "Epoch 78/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1539 - accuracy: 0.9356 - val_loss: 0.2500 - val_accuracy: 0.9128\n",
            "Epoch 79/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9356 - val_loss: 0.2491 - val_accuracy: 0.9092\n",
            "Epoch 80/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1479 - accuracy: 0.9368 - val_loss: 0.2419 - val_accuracy: 0.9152\n",
            "Epoch 81/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1476 - accuracy: 0.9370 - val_loss: 0.2467 - val_accuracy: 0.9152\n",
            "Epoch 82/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1502 - accuracy: 0.9369 - val_loss: 0.2561 - val_accuracy: 0.9088\n",
            "Epoch 83/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1476 - accuracy: 0.9375 - val_loss: 0.2764 - val_accuracy: 0.8919\n",
            "Epoch 84/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1501 - accuracy: 0.9364 - val_loss: 0.2715 - val_accuracy: 0.9124\n",
            "Epoch 85/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1469 - accuracy: 0.9389 - val_loss: 0.2444 - val_accuracy: 0.9142\n",
            "Epoch 86/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1466 - accuracy: 0.9372 - val_loss: 0.2467 - val_accuracy: 0.9119\n",
            "Epoch 87/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1451 - accuracy: 0.9393 - val_loss: 0.2562 - val_accuracy: 0.9156\n",
            "Epoch 88/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1443 - accuracy: 0.9388 - val_loss: 0.2590 - val_accuracy: 0.9130\n",
            "Epoch 89/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1440 - accuracy: 0.9393 - val_loss: 0.2634 - val_accuracy: 0.9105\n",
            "Epoch 90/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1399 - accuracy: 0.9404 - val_loss: 0.2585 - val_accuracy: 0.9053\n",
            "Epoch 91/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1423 - accuracy: 0.9395 - val_loss: 0.2586 - val_accuracy: 0.9110\n",
            "Epoch 92/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1416 - accuracy: 0.9408 - val_loss: 0.2555 - val_accuracy: 0.9107\n",
            "Epoch 93/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1378 - accuracy: 0.9395 - val_loss: 0.2728 - val_accuracy: 0.9141\n",
            "Epoch 94/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1419 - accuracy: 0.9394 - val_loss: 0.2666 - val_accuracy: 0.9167\n",
            "Epoch 95/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1391 - accuracy: 0.9417 - val_loss: 0.2699 - val_accuracy: 0.9114\n",
            "Epoch 96/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1386 - accuracy: 0.9411 - val_loss: 0.2589 - val_accuracy: 0.9191\n",
            "Epoch 97/500\n",
            "575/575 [==============================] - 2s 3ms/step - loss: 0.1357 - accuracy: 0.9427 - val_loss: 0.2602 - val_accuracy: 0.9096\n",
            "Epoch 98/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1404 - accuracy: 0.9402 - val_loss: 0.2693 - val_accuracy: 0.9137\n",
            "Epoch 99/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1344 - accuracy: 0.9440 - val_loss: 0.2767 - val_accuracy: 0.9088\n",
            "Epoch 100/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9445 - val_loss: 0.2595 - val_accuracy: 0.9156\n",
            "Epoch 101/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9420 - val_loss: 0.2728 - val_accuracy: 0.9098\n",
            "Epoch 102/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9448 - val_loss: 0.2685 - val_accuracy: 0.9114\n",
            "Epoch 103/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9439 - val_loss: 0.2767 - val_accuracy: 0.9103\n",
            "Epoch 104/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1299 - accuracy: 0.9455 - val_loss: 0.2582 - val_accuracy: 0.9164\n",
            "Epoch 105/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1306 - accuracy: 0.9448 - val_loss: 0.2784 - val_accuracy: 0.9145\n",
            "Epoch 106/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1299 - accuracy: 0.9454 - val_loss: 0.2828 - val_accuracy: 0.9137\n",
            "Epoch 107/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1306 - accuracy: 0.9466 - val_loss: 0.2880 - val_accuracy: 0.9114\n",
            "Epoch 108/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1273 - accuracy: 0.9466 - val_loss: 0.2791 - val_accuracy: 0.9137\n",
            "Epoch 109/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9455 - val_loss: 0.2787 - val_accuracy: 0.9109\n",
            "Epoch 110/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1285 - accuracy: 0.9466 - val_loss: 0.2719 - val_accuracy: 0.9114\n",
            "Epoch 111/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9449 - val_loss: 0.2842 - val_accuracy: 0.9103\n",
            "Epoch 112/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9459 - val_loss: 0.2845 - val_accuracy: 0.9077\n",
            "Epoch 113/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1283 - accuracy: 0.9461 - val_loss: 0.2797 - val_accuracy: 0.9124\n",
            "Epoch 114/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1238 - accuracy: 0.9465 - val_loss: 0.2862 - val_accuracy: 0.9117\n",
            "Epoch 115/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1242 - accuracy: 0.9486 - val_loss: 0.2941 - val_accuracy: 0.9138\n",
            "Epoch 116/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1242 - accuracy: 0.9480 - val_loss: 0.2818 - val_accuracy: 0.9163\n",
            "Epoch 117/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1216 - accuracy: 0.9486 - val_loss: 0.2795 - val_accuracy: 0.9155\n",
            "Epoch 118/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1238 - accuracy: 0.9481 - val_loss: 0.2923 - val_accuracy: 0.9110\n",
            "Epoch 119/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1219 - accuracy: 0.9490 - val_loss: 0.2899 - val_accuracy: 0.9160\n",
            "Epoch 120/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9484 - val_loss: 0.2920 - val_accuracy: 0.9167\n",
            "Epoch 121/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1216 - accuracy: 0.9489 - val_loss: 0.2844 - val_accuracy: 0.9148\n",
            "Epoch 122/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1173 - accuracy: 0.9505 - val_loss: 0.2874 - val_accuracy: 0.9159\n",
            "Epoch 123/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1209 - accuracy: 0.9484 - val_loss: 0.2990 - val_accuracy: 0.9153\n",
            "Epoch 124/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1247 - accuracy: 0.9471 - val_loss: 0.2915 - val_accuracy: 0.9138\n",
            "Epoch 125/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1255 - accuracy: 0.9493 - val_loss: 0.3108 - val_accuracy: 0.9177\n",
            "Epoch 126/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.9510 - val_loss: 0.3058 - val_accuracy: 0.9156\n",
            "Epoch 127/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1202 - accuracy: 0.9513 - val_loss: 0.2859 - val_accuracy: 0.9125\n",
            "Epoch 128/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1191 - accuracy: 0.9509 - val_loss: 0.3025 - val_accuracy: 0.9124\n",
            "Epoch 129/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1166 - accuracy: 0.9512 - val_loss: 0.2957 - val_accuracy: 0.9199\n",
            "Epoch 130/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1126 - accuracy: 0.9544 - val_loss: 0.3079 - val_accuracy: 0.9141\n",
            "Epoch 131/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1152 - accuracy: 0.9521 - val_loss: 0.2992 - val_accuracy: 0.9156\n",
            "Epoch 132/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1159 - accuracy: 0.9506 - val_loss: 0.3115 - val_accuracy: 0.9138\n",
            "Epoch 133/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1175 - accuracy: 0.9512 - val_loss: 0.3187 - val_accuracy: 0.9102\n",
            "Epoch 134/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1144 - accuracy: 0.9519 - val_loss: 0.3125 - val_accuracy: 0.9176\n",
            "Epoch 135/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1191 - accuracy: 0.9500 - val_loss: 0.3101 - val_accuracy: 0.9167\n",
            "Epoch 136/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1148 - accuracy: 0.9527 - val_loss: 0.3195 - val_accuracy: 0.9131\n",
            "Epoch 137/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1157 - accuracy: 0.9516 - val_loss: 0.3031 - val_accuracy: 0.9176\n",
            "Epoch 138/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1138 - accuracy: 0.9523 - val_loss: 0.3297 - val_accuracy: 0.9110\n",
            "Epoch 139/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1108 - accuracy: 0.9532 - val_loss: 0.3180 - val_accuracy: 0.9142\n",
            "Epoch 140/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9513 - val_loss: 0.3275 - val_accuracy: 0.9088\n",
            "Epoch 141/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1099 - accuracy: 0.9546 - val_loss: 0.3356 - val_accuracy: 0.9144\n",
            "Epoch 142/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9535 - val_loss: 0.3288 - val_accuracy: 0.9135\n",
            "Epoch 143/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1094 - accuracy: 0.9537 - val_loss: 0.3198 - val_accuracy: 0.9153\n",
            "Epoch 144/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.3353 - val_accuracy: 0.9151\n",
            "Epoch 145/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1249 - accuracy: 0.9520 - val_loss: 0.3260 - val_accuracy: 0.9156\n",
            "Epoch 146/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1136 - accuracy: 0.9540 - val_loss: 0.3231 - val_accuracy: 0.9170\n",
            "Epoch 147/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1078 - accuracy: 0.9547 - val_loss: 0.3177 - val_accuracy: 0.9213\n",
            "Epoch 148/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9559 - val_loss: 0.3375 - val_accuracy: 0.9116\n",
            "Epoch 149/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1072 - accuracy: 0.9559 - val_loss: 0.3168 - val_accuracy: 0.9145\n",
            "Epoch 150/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1084 - accuracy: 0.9561 - val_loss: 0.3237 - val_accuracy: 0.9113\n",
            "Epoch 151/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9548 - val_loss: 0.3397 - val_accuracy: 0.9178\n",
            "Epoch 152/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9564 - val_loss: 0.3555 - val_accuracy: 0.9106\n",
            "Epoch 153/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1053 - accuracy: 0.9573 - val_loss: 0.3367 - val_accuracy: 0.9139\n",
            "Epoch 154/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1064 - accuracy: 0.9567 - val_loss: 0.3290 - val_accuracy: 0.9155\n",
            "Epoch 155/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1030 - accuracy: 0.9572 - val_loss: 0.3375 - val_accuracy: 0.9159\n",
            "Epoch 156/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1084 - accuracy: 0.9542 - val_loss: 0.3222 - val_accuracy: 0.9159\n",
            "Epoch 157/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1040 - accuracy: 0.9580 - val_loss: 0.3383 - val_accuracy: 0.9139\n",
            "Epoch 158/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1072 - accuracy: 0.9559 - val_loss: 0.3336 - val_accuracy: 0.9120\n",
            "Epoch 159/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1039 - accuracy: 0.9564 - val_loss: 0.3342 - val_accuracy: 0.9162\n",
            "Epoch 160/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.9579 - val_loss: 0.3427 - val_accuracy: 0.9098\n",
            "Epoch 161/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9578 - val_loss: 0.3477 - val_accuracy: 0.9135\n",
            "Epoch 162/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1111 - accuracy: 0.9550 - val_loss: 0.3405 - val_accuracy: 0.9106\n",
            "Epoch 163/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1058 - accuracy: 0.9567 - val_loss: 0.3160 - val_accuracy: 0.9183\n",
            "Epoch 164/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1049 - accuracy: 0.9563 - val_loss: 0.3280 - val_accuracy: 0.9132\n",
            "Epoch 165/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9576 - val_loss: 0.3395 - val_accuracy: 0.9190\n",
            "Epoch 166/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0962 - accuracy: 0.9595 - val_loss: 0.3486 - val_accuracy: 0.9149\n",
            "Epoch 167/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1062 - accuracy: 0.9557 - val_loss: 0.3421 - val_accuracy: 0.9174\n",
            "Epoch 168/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0991 - accuracy: 0.9593 - val_loss: 0.3423 - val_accuracy: 0.9167\n",
            "Epoch 169/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0995 - accuracy: 0.9596 - val_loss: 0.3461 - val_accuracy: 0.9173\n",
            "Epoch 170/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1016 - accuracy: 0.9576 - val_loss: 0.3340 - val_accuracy: 0.9102\n",
            "Epoch 171/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9603 - val_loss: 0.3700 - val_accuracy: 0.9123\n",
            "Epoch 172/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0978 - accuracy: 0.9595 - val_loss: 0.3481 - val_accuracy: 0.9134\n",
            "Epoch 173/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9598 - val_loss: 0.3411 - val_accuracy: 0.9123\n",
            "Epoch 174/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0969 - accuracy: 0.9592 - val_loss: 0.3618 - val_accuracy: 0.9139\n",
            "Epoch 175/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0987 - accuracy: 0.9585 - val_loss: 0.3564 - val_accuracy: 0.9166\n",
            "Epoch 176/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0945 - accuracy: 0.9604 - val_loss: 0.3605 - val_accuracy: 0.9151\n",
            "Epoch 177/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0938 - accuracy: 0.9617 - val_loss: 0.3757 - val_accuracy: 0.9166\n",
            "Epoch 178/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9606 - val_loss: 0.3782 - val_accuracy: 0.9116\n",
            "Epoch 179/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0987 - accuracy: 0.9592 - val_loss: 0.3655 - val_accuracy: 0.9098\n",
            "Epoch 180/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9600 - val_loss: 0.3697 - val_accuracy: 0.9119\n",
            "Epoch 181/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0964 - accuracy: 0.9603 - val_loss: 0.3572 - val_accuracy: 0.9176\n",
            "Epoch 182/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1120 - accuracy: 0.9561 - val_loss: 0.3846 - val_accuracy: 0.9068\n",
            "Epoch 183/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0958 - accuracy: 0.9608 - val_loss: 0.3437 - val_accuracy: 0.9149\n",
            "Epoch 184/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9624 - val_loss: 0.3669 - val_accuracy: 0.9174\n",
            "Epoch 185/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0948 - accuracy: 0.9610 - val_loss: 0.3587 - val_accuracy: 0.9152\n",
            "Epoch 186/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0914 - accuracy: 0.9613 - val_loss: 0.3683 - val_accuracy: 0.9157\n",
            "Epoch 187/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9626 - val_loss: 0.3742 - val_accuracy: 0.9185\n",
            "Epoch 188/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9627 - val_loss: 0.3524 - val_accuracy: 0.9144\n",
            "Epoch 189/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0911 - accuracy: 0.9631 - val_loss: 0.3747 - val_accuracy: 0.9166\n",
            "Epoch 190/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0945 - accuracy: 0.9610 - val_loss: 0.3803 - val_accuracy: 0.9163\n",
            "Epoch 191/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9600 - val_loss: 0.3904 - val_accuracy: 0.9130\n",
            "Epoch 192/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9615 - val_loss: 0.3727 - val_accuracy: 0.9174\n",
            "Epoch 193/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9630 - val_loss: 0.3864 - val_accuracy: 0.9163\n",
            "Epoch 194/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0915 - accuracy: 0.9628 - val_loss: 0.4037 - val_accuracy: 0.9112\n",
            "Epoch 195/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.9637 - val_loss: 0.3868 - val_accuracy: 0.9132\n",
            "Epoch 196/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9625 - val_loss: 0.3880 - val_accuracy: 0.9119\n",
            "Epoch 197/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.3890 - val_accuracy: 0.9137\n",
            "Epoch 198/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0919 - accuracy: 0.9637 - val_loss: 0.3793 - val_accuracy: 0.9177\n",
            "Epoch 199/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9651 - val_loss: 0.3900 - val_accuracy: 0.9134\n",
            "Epoch 200/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0915 - accuracy: 0.9622 - val_loss: 0.3597 - val_accuracy: 0.9144\n",
            "Epoch 201/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9640 - val_loss: 0.3833 - val_accuracy: 0.9135\n",
            "Epoch 202/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0888 - accuracy: 0.9645 - val_loss: 0.4048 - val_accuracy: 0.9139\n",
            "Epoch 203/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9630 - val_loss: 0.3817 - val_accuracy: 0.9131\n",
            "Epoch 204/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9635 - val_loss: 0.4241 - val_accuracy: 0.9166\n",
            "Epoch 205/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9624 - val_loss: 0.3704 - val_accuracy: 0.9163\n",
            "Epoch 206/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9637 - val_loss: 0.3978 - val_accuracy: 0.9110\n",
            "Epoch 207/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9638 - val_loss: 0.3946 - val_accuracy: 0.9148\n",
            "Epoch 208/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9640 - val_loss: 0.4216 - val_accuracy: 0.9139\n",
            "Epoch 209/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9614 - val_loss: 0.3868 - val_accuracy: 0.9141\n",
            "Epoch 210/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0848 - accuracy: 0.9642 - val_loss: 0.3906 - val_accuracy: 0.9132\n",
            "Epoch 211/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0805 - accuracy: 0.9656 - val_loss: 0.3974 - val_accuracy: 0.9166\n",
            "Epoch 212/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9617 - val_loss: 0.4059 - val_accuracy: 0.9146\n",
            "Epoch 213/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9642 - val_loss: 0.4141 - val_accuracy: 0.9142\n",
            "Epoch 214/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.3979 - val_accuracy: 0.9145\n",
            "Epoch 215/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0855 - accuracy: 0.9639 - val_loss: 0.3956 - val_accuracy: 0.9130\n",
            "Epoch 216/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9641 - val_loss: 0.4182 - val_accuracy: 0.9155\n",
            "Epoch 217/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9643 - val_loss: 0.4024 - val_accuracy: 0.9160\n",
            "Epoch 218/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0840 - accuracy: 0.9658 - val_loss: 0.3989 - val_accuracy: 0.9153\n",
            "Epoch 219/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9673 - val_loss: 0.4202 - val_accuracy: 0.9142\n",
            "Epoch 220/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0886 - accuracy: 0.9636 - val_loss: 0.4228 - val_accuracy: 0.9162\n",
            "Epoch 221/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0792 - accuracy: 0.9687 - val_loss: 0.4312 - val_accuracy: 0.9134\n",
            "Epoch 222/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.9650 - val_loss: 0.4030 - val_accuracy: 0.9149\n",
            "Epoch 223/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.9651 - val_loss: 0.4072 - val_accuracy: 0.9191\n",
            "Epoch 224/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0904 - accuracy: 0.9632 - val_loss: 0.3932 - val_accuracy: 0.9106\n",
            "Epoch 225/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9662 - val_loss: 0.4321 - val_accuracy: 0.9132\n",
            "Epoch 226/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0799 - accuracy: 0.9674 - val_loss: 0.4352 - val_accuracy: 0.9169\n",
            "Epoch 227/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9659 - val_loss: 0.4121 - val_accuracy: 0.9106\n",
            "Epoch 228/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0837 - accuracy: 0.9651 - val_loss: 0.4447 - val_accuracy: 0.9117\n",
            "Epoch 229/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9669 - val_loss: 0.4136 - val_accuracy: 0.9145\n",
            "Epoch 230/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0866 - accuracy: 0.9663 - val_loss: 0.4357 - val_accuracy: 0.9103\n",
            "Epoch 231/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0814 - accuracy: 0.9662 - val_loss: 0.4601 - val_accuracy: 0.9155\n",
            "Epoch 232/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0841 - accuracy: 0.9664 - val_loss: 0.4512 - val_accuracy: 0.9123\n",
            "Epoch 233/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9675 - val_loss: 0.4667 - val_accuracy: 0.9128\n",
            "Epoch 234/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9692 - val_loss: 0.4193 - val_accuracy: 0.9178\n",
            "Epoch 235/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9684 - val_loss: 0.4479 - val_accuracy: 0.9151\n",
            "Epoch 236/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0840 - accuracy: 0.9666 - val_loss: 0.4672 - val_accuracy: 0.9070\n",
            "Epoch 237/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9659 - val_loss: 0.4385 - val_accuracy: 0.9173\n",
            "Epoch 238/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0944 - accuracy: 0.9648 - val_loss: 0.4111 - val_accuracy: 0.9112\n",
            "Epoch 239/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0914 - accuracy: 0.9663 - val_loss: 0.4060 - val_accuracy: 0.9099\n",
            "Epoch 240/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0784 - accuracy: 0.9689 - val_loss: 0.4193 - val_accuracy: 0.9171\n",
            "Epoch 241/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0755 - accuracy: 0.9692 - val_loss: 0.4379 - val_accuracy: 0.9169\n",
            "Epoch 242/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9678 - val_loss: 0.4454 - val_accuracy: 0.9157\n",
            "Epoch 243/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0784 - accuracy: 0.9675 - val_loss: 0.4421 - val_accuracy: 0.9171\n",
            "Epoch 244/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0794 - accuracy: 0.9679 - val_loss: 0.4171 - val_accuracy: 0.9138\n",
            "Epoch 245/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9670 - val_loss: 0.4359 - val_accuracy: 0.9155\n",
            "Epoch 246/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.4474 - val_accuracy: 0.9124\n",
            "Epoch 247/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0744 - accuracy: 0.9707 - val_loss: 0.4518 - val_accuracy: 0.9125\n",
            "Epoch 248/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0807 - accuracy: 0.9671 - val_loss: 0.4246 - val_accuracy: 0.9163\n",
            "Epoch 249/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9693 - val_loss: 0.4567 - val_accuracy: 0.9160\n",
            "Epoch 250/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9667 - val_loss: 0.4255 - val_accuracy: 0.9159\n",
            "Epoch 251/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9703 - val_loss: 0.4505 - val_accuracy: 0.9128\n",
            "Epoch 252/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0754 - accuracy: 0.9689 - val_loss: 0.4956 - val_accuracy: 0.9125\n",
            "Epoch 253/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9678 - val_loss: 0.4287 - val_accuracy: 0.9128\n",
            "Epoch 254/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.9682 - val_loss: 0.4414 - val_accuracy: 0.9123\n",
            "Epoch 255/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0814 - accuracy: 0.9683 - val_loss: 0.4346 - val_accuracy: 0.9176\n",
            "Epoch 256/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9667 - val_loss: 0.4454 - val_accuracy: 0.9176\n",
            "Epoch 257/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9702 - val_loss: 0.4528 - val_accuracy: 0.9174\n",
            "Epoch 258/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9706 - val_loss: 0.4656 - val_accuracy: 0.9121\n",
            "Epoch 259/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9700 - val_loss: 0.4799 - val_accuracy: 0.9088\n",
            "Epoch 260/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9677 - val_loss: 0.5229 - val_accuracy: 0.9116\n",
            "Epoch 261/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0962 - accuracy: 0.9654 - val_loss: 0.5066 - val_accuracy: 0.9163\n",
            "Epoch 262/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9673 - val_loss: 0.4779 - val_accuracy: 0.9138\n",
            "Epoch 263/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0733 - accuracy: 0.9705 - val_loss: 0.4868 - val_accuracy: 0.9170\n",
            "Epoch 264/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9708 - val_loss: 0.4964 - val_accuracy: 0.9160\n",
            "Epoch 265/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0708 - accuracy: 0.9708 - val_loss: 0.4842 - val_accuracy: 0.9132\n",
            "Epoch 266/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9678 - val_loss: 0.4777 - val_accuracy: 0.9169\n",
            "Epoch 267/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9718 - val_loss: 0.4794 - val_accuracy: 0.9099\n",
            "Epoch 268/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0807 - accuracy: 0.9691 - val_loss: 0.5391 - val_accuracy: 0.9077\n",
            "Epoch 269/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9702 - val_loss: 0.4831 - val_accuracy: 0.9131\n",
            "Epoch 270/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0815 - accuracy: 0.9685 - val_loss: 0.4531 - val_accuracy: 0.9160\n",
            "Epoch 271/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0692 - accuracy: 0.9736 - val_loss: 0.4634 - val_accuracy: 0.9088\n",
            "Epoch 272/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9690 - val_loss: 0.4746 - val_accuracy: 0.9138\n",
            "Epoch 273/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.9701 - val_loss: 0.4697 - val_accuracy: 0.9156\n",
            "Epoch 274/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0763 - accuracy: 0.9691 - val_loss: 0.4525 - val_accuracy: 0.9130\n",
            "Epoch 275/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0688 - accuracy: 0.9716 - val_loss: 0.4586 - val_accuracy: 0.9135\n",
            "Epoch 276/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9701 - val_loss: 0.5217 - val_accuracy: 0.9110\n",
            "Epoch 277/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9689 - val_loss: 0.4520 - val_accuracy: 0.9176\n",
            "Epoch 278/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9719 - val_loss: 0.5078 - val_accuracy: 0.9121\n",
            "Epoch 279/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9712 - val_loss: 0.4642 - val_accuracy: 0.9119\n",
            "Epoch 280/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9687 - val_loss: 0.4645 - val_accuracy: 0.9134\n",
            "Epoch 281/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0732 - accuracy: 0.9711 - val_loss: 0.5059 - val_accuracy: 0.9164\n",
            "Epoch 282/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9695 - val_loss: 0.4910 - val_accuracy: 0.9142\n",
            "Epoch 283/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0738 - accuracy: 0.9706 - val_loss: 0.5141 - val_accuracy: 0.9159\n",
            "Epoch 284/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0808 - accuracy: 0.9680 - val_loss: 0.4531 - val_accuracy: 0.9177\n",
            "Epoch 285/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9716 - val_loss: 0.4841 - val_accuracy: 0.9102\n",
            "Epoch 286/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9716 - val_loss: 0.5215 - val_accuracy: 0.9141\n",
            "Epoch 287/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9721 - val_loss: 0.4975 - val_accuracy: 0.9107\n",
            "Epoch 288/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9719 - val_loss: 0.5017 - val_accuracy: 0.9176\n",
            "Epoch 289/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.9701 - val_loss: 0.4942 - val_accuracy: 0.9124\n",
            "Epoch 290/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0701 - accuracy: 0.9709 - val_loss: 0.5385 - val_accuracy: 0.9152\n",
            "Epoch 291/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0665 - accuracy: 0.9727 - val_loss: 0.4644 - val_accuracy: 0.9128\n",
            "Epoch 292/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0715 - accuracy: 0.9710 - val_loss: 0.4971 - val_accuracy: 0.9086\n",
            "Epoch 293/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0718 - accuracy: 0.9716 - val_loss: 0.5041 - val_accuracy: 0.9139\n",
            "Epoch 294/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9710 - val_loss: 0.4845 - val_accuracy: 0.9134\n",
            "Epoch 295/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0764 - accuracy: 0.9707 - val_loss: 0.4878 - val_accuracy: 0.9156\n",
            "Epoch 296/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0723 - accuracy: 0.9724 - val_loss: 0.5249 - val_accuracy: 0.9159\n",
            "Epoch 297/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9725 - val_loss: 0.4921 - val_accuracy: 0.9146\n",
            "Epoch 298/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0761 - accuracy: 0.9695 - val_loss: 0.5254 - val_accuracy: 0.9082\n",
            "Epoch 299/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0746 - accuracy: 0.9706 - val_loss: 0.4984 - val_accuracy: 0.9137\n",
            "Epoch 300/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9739 - val_loss: 0.4873 - val_accuracy: 0.9144\n",
            "Epoch 301/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0708 - accuracy: 0.9724 - val_loss: 0.4912 - val_accuracy: 0.9085\n",
            "Epoch 302/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9705 - val_loss: 0.4936 - val_accuracy: 0.9112\n",
            "Epoch 303/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9724 - val_loss: 0.4713 - val_accuracy: 0.9145\n",
            "Epoch 304/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9727 - val_loss: 0.5261 - val_accuracy: 0.9146\n",
            "Epoch 305/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0683 - accuracy: 0.9720 - val_loss: 0.4694 - val_accuracy: 0.9163\n",
            "Epoch 306/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.9727 - val_loss: 0.4910 - val_accuracy: 0.9192\n",
            "Epoch 307/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9715 - val_loss: 0.5140 - val_accuracy: 0.9176\n",
            "Epoch 308/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9746 - val_loss: 0.5074 - val_accuracy: 0.9153\n",
            "Epoch 309/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9689 - val_loss: 0.5350 - val_accuracy: 0.9127\n",
            "Epoch 310/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9722 - val_loss: 0.4965 - val_accuracy: 0.9181\n",
            "Epoch 311/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9739 - val_loss: 0.4786 - val_accuracy: 0.9174\n",
            "Epoch 312/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9726 - val_loss: 0.5299 - val_accuracy: 0.9107\n",
            "Epoch 313/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0663 - accuracy: 0.9720 - val_loss: 0.5341 - val_accuracy: 0.9113\n",
            "Epoch 314/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9694 - val_loss: 0.4728 - val_accuracy: 0.9134\n",
            "Epoch 315/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9721 - val_loss: 0.5073 - val_accuracy: 0.9148\n",
            "Epoch 316/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0655 - accuracy: 0.9735 - val_loss: 0.5433 - val_accuracy: 0.9123\n",
            "Epoch 317/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9742 - val_loss: 0.5586 - val_accuracy: 0.9086\n",
            "Epoch 318/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.1097 - accuracy: 0.9682 - val_loss: 0.5086 - val_accuracy: 0.9160\n",
            "Epoch 319/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9757 - val_loss: 0.5174 - val_accuracy: 0.9135\n",
            "Epoch 320/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.9764 - val_loss: 0.5228 - val_accuracy: 0.9170\n",
            "Epoch 321/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9745 - val_loss: 0.5660 - val_accuracy: 0.9160\n",
            "Epoch 322/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0697 - accuracy: 0.9729 - val_loss: 0.5157 - val_accuracy: 0.9098\n",
            "Epoch 323/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9737 - val_loss: 0.5351 - val_accuracy: 0.9102\n",
            "Epoch 324/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0657 - accuracy: 0.9731 - val_loss: 0.5150 - val_accuracy: 0.9170\n",
            "Epoch 325/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.9739 - val_loss: 0.5041 - val_accuracy: 0.9142\n",
            "Epoch 326/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9750 - val_loss: 0.5344 - val_accuracy: 0.9169\n",
            "Epoch 327/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0685 - accuracy: 0.9732 - val_loss: 0.5328 - val_accuracy: 0.9139\n",
            "Epoch 328/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.9746 - val_loss: 0.5890 - val_accuracy: 0.9092\n",
            "Epoch 329/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0681 - accuracy: 0.9734 - val_loss: 0.5553 - val_accuracy: 0.9146\n",
            "Epoch 330/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9730 - val_loss: 0.4982 - val_accuracy: 0.9119\n",
            "Epoch 331/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9753 - val_loss: 0.6036 - val_accuracy: 0.9127\n",
            "Epoch 332/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 0.5528 - val_accuracy: 0.9137\n",
            "Epoch 333/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9739 - val_loss: 0.5598 - val_accuracy: 0.9174\n",
            "Epoch 334/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0638 - accuracy: 0.9747 - val_loss: 0.5490 - val_accuracy: 0.9105\n",
            "Epoch 335/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9744 - val_loss: 0.5158 - val_accuracy: 0.9142\n",
            "Epoch 336/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9744 - val_loss: 0.5481 - val_accuracy: 0.9160\n",
            "Epoch 337/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9739 - val_loss: 0.5330 - val_accuracy: 0.9103\n",
            "Epoch 338/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9726 - val_loss: 0.5795 - val_accuracy: 0.9134\n",
            "Epoch 339/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9715 - val_loss: 0.5567 - val_accuracy: 0.9144\n",
            "Epoch 340/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9725 - val_loss: 0.5521 - val_accuracy: 0.9120\n",
            "Epoch 341/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9726 - val_loss: 0.5574 - val_accuracy: 0.9123\n",
            "Epoch 342/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0644 - accuracy: 0.9754 - val_loss: 0.5755 - val_accuracy: 0.9180\n",
            "Epoch 343/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0601 - accuracy: 0.9762 - val_loss: 0.5915 - val_accuracy: 0.9151\n",
            "Epoch 344/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9726 - val_loss: 0.5564 - val_accuracy: 0.9151\n",
            "Epoch 345/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0658 - accuracy: 0.9751 - val_loss: 0.5081 - val_accuracy: 0.9164\n",
            "Epoch 346/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9744 - val_loss: 0.5427 - val_accuracy: 0.9124\n",
            "Epoch 347/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.5619 - val_accuracy: 0.9146\n",
            "Epoch 348/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0694 - accuracy: 0.9729 - val_loss: 0.5165 - val_accuracy: 0.9164\n",
            "Epoch 349/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9760 - val_loss: 0.5628 - val_accuracy: 0.9174\n",
            "Epoch 350/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.9759 - val_loss: 0.5752 - val_accuracy: 0.9163\n",
            "Epoch 351/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.9725 - val_loss: 0.5274 - val_accuracy: 0.9148\n",
            "Epoch 352/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0596 - accuracy: 0.9767 - val_loss: 0.5317 - val_accuracy: 0.9167\n",
            "Epoch 353/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0645 - accuracy: 0.9743 - val_loss: 0.5569 - val_accuracy: 0.9078\n",
            "Epoch 354/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0661 - accuracy: 0.9748 - val_loss: 0.5625 - val_accuracy: 0.9088\n",
            "Epoch 355/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0703 - accuracy: 0.9727 - val_loss: 0.5514 - val_accuracy: 0.9139\n",
            "Epoch 356/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9756 - val_loss: 0.5685 - val_accuracy: 0.9148\n",
            "Epoch 357/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0620 - accuracy: 0.9744 - val_loss: 0.5587 - val_accuracy: 0.9116\n",
            "Epoch 358/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9771 - val_loss: 0.5839 - val_accuracy: 0.9103\n",
            "Epoch 359/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0609 - accuracy: 0.9766 - val_loss: 0.5970 - val_accuracy: 0.9134\n",
            "Epoch 360/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9747 - val_loss: 0.6009 - val_accuracy: 0.9109\n",
            "Epoch 361/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0650 - accuracy: 0.9749 - val_loss: 0.6234 - val_accuracy: 0.9098\n",
            "Epoch 362/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0676 - accuracy: 0.9735 - val_loss: 0.5520 - val_accuracy: 0.9151\n",
            "Epoch 363/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9750 - val_loss: 0.6053 - val_accuracy: 0.9106\n",
            "Epoch 364/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9761 - val_loss: 0.6082 - val_accuracy: 0.9145\n",
            "Epoch 365/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0624 - accuracy: 0.9753 - val_loss: 0.5709 - val_accuracy: 0.9185\n",
            "Epoch 366/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9753 - val_loss: 0.5831 - val_accuracy: 0.9137\n",
            "Epoch 367/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0618 - accuracy: 0.9771 - val_loss: 0.6299 - val_accuracy: 0.9095\n",
            "Epoch 368/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.5478 - val_accuracy: 0.9141\n",
            "Epoch 369/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0602 - accuracy: 0.9763 - val_loss: 0.5727 - val_accuracy: 0.9151\n",
            "Epoch 370/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0616 - accuracy: 0.9752 - val_loss: 0.5844 - val_accuracy: 0.9096\n",
            "Epoch 371/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0623 - accuracy: 0.9750 - val_loss: 0.5927 - val_accuracy: 0.9145\n",
            "Epoch 372/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9747 - val_loss: 0.5451 - val_accuracy: 0.9171\n",
            "Epoch 373/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0526 - accuracy: 0.9784 - val_loss: 0.6181 - val_accuracy: 0.9130\n",
            "Epoch 374/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0668 - accuracy: 0.9740 - val_loss: 0.5727 - val_accuracy: 0.9103\n",
            "Epoch 375/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.9759 - val_loss: 0.6646 - val_accuracy: 0.9075\n",
            "Epoch 376/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9770 - val_loss: 0.5856 - val_accuracy: 0.9145\n",
            "Epoch 377/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9760 - val_loss: 0.6234 - val_accuracy: 0.9117\n",
            "Epoch 378/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0609 - accuracy: 0.9760 - val_loss: 0.5992 - val_accuracy: 0.9177\n",
            "Epoch 379/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9752 - val_loss: 0.6042 - val_accuracy: 0.9128\n",
            "Epoch 380/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9753 - val_loss: 0.5626 - val_accuracy: 0.9149\n",
            "Epoch 381/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0643 - accuracy: 0.9758 - val_loss: 0.5864 - val_accuracy: 0.9130\n",
            "Epoch 382/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9751 - val_loss: 0.5778 - val_accuracy: 0.9123\n",
            "Epoch 383/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0661 - accuracy: 0.9740 - val_loss: 0.5900 - val_accuracy: 0.9124\n",
            "Epoch 384/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0590 - accuracy: 0.9778 - val_loss: 0.6012 - val_accuracy: 0.9095\n",
            "Epoch 385/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0565 - accuracy: 0.9787 - val_loss: 0.5904 - val_accuracy: 0.9144\n",
            "Epoch 386/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.6039 - val_accuracy: 0.9112\n",
            "Epoch 387/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0583 - accuracy: 0.9769 - val_loss: 0.5970 - val_accuracy: 0.9142\n",
            "Epoch 388/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9774 - val_loss: 0.6207 - val_accuracy: 0.9125\n",
            "Epoch 389/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 0.6106 - val_accuracy: 0.9145\n",
            "Epoch 390/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0650 - accuracy: 0.9748 - val_loss: 0.5816 - val_accuracy: 0.9166\n",
            "Epoch 391/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9767 - val_loss: 0.5874 - val_accuracy: 0.9157\n",
            "Epoch 392/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0551 - accuracy: 0.9776 - val_loss: 0.6289 - val_accuracy: 0.9135\n",
            "Epoch 393/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9752 - val_loss: 0.5937 - val_accuracy: 0.9178\n",
            "Epoch 394/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0595 - accuracy: 0.9774 - val_loss: 0.5852 - val_accuracy: 0.9138\n",
            "Epoch 395/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0616 - accuracy: 0.9773 - val_loss: 0.5857 - val_accuracy: 0.9117\n",
            "Epoch 396/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9782 - val_loss: 0.6165 - val_accuracy: 0.9124\n",
            "Epoch 397/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9758 - val_loss: 0.5911 - val_accuracy: 0.9148\n",
            "Epoch 398/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.9781 - val_loss: 0.5923 - val_accuracy: 0.9152\n",
            "Epoch 399/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9764 - val_loss: 0.6288 - val_accuracy: 0.9060\n",
            "Epoch 400/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0584 - accuracy: 0.9765 - val_loss: 0.6169 - val_accuracy: 0.9146\n",
            "Epoch 401/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0657 - accuracy: 0.9743 - val_loss: 0.6083 - val_accuracy: 0.9123\n",
            "Epoch 402/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0555 - accuracy: 0.9785 - val_loss: 0.5971 - val_accuracy: 0.9152\n",
            "Epoch 403/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0591 - accuracy: 0.9772 - val_loss: 0.6174 - val_accuracy: 0.9112\n",
            "Epoch 404/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0641 - accuracy: 0.9755 - val_loss: 0.6334 - val_accuracy: 0.9099\n",
            "Epoch 405/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9772 - val_loss: 0.6067 - val_accuracy: 0.9144\n",
            "Epoch 406/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0563 - accuracy: 0.9785 - val_loss: 0.6723 - val_accuracy: 0.9138\n",
            "Epoch 407/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0575 - accuracy: 0.9766 - val_loss: 0.6404 - val_accuracy: 0.9124\n",
            "Epoch 408/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9772 - val_loss: 0.6061 - val_accuracy: 0.9141\n",
            "Epoch 409/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9767 - val_loss: 0.6055 - val_accuracy: 0.9134\n",
            "Epoch 410/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0637 - accuracy: 0.9767 - val_loss: 0.5852 - val_accuracy: 0.9156\n",
            "Epoch 411/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9779 - val_loss: 0.5898 - val_accuracy: 0.9180\n",
            "Epoch 412/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0601 - accuracy: 0.9768 - val_loss: 0.6126 - val_accuracy: 0.9151\n",
            "Epoch 413/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0540 - accuracy: 0.9787 - val_loss: 0.6350 - val_accuracy: 0.9127\n",
            "Epoch 414/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0534 - accuracy: 0.9788 - val_loss: 0.6455 - val_accuracy: 0.9148\n",
            "Epoch 415/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9768 - val_loss: 0.6398 - val_accuracy: 0.9095\n",
            "Epoch 416/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0633 - accuracy: 0.9759 - val_loss: 0.6112 - val_accuracy: 0.9134\n",
            "Epoch 417/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0617 - accuracy: 0.9770 - val_loss: 0.6153 - val_accuracy: 0.9117\n",
            "Epoch 418/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9787 - val_loss: 0.6382 - val_accuracy: 0.9119\n",
            "Epoch 419/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9767 - val_loss: 0.6015 - val_accuracy: 0.9124\n",
            "Epoch 420/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9806 - val_loss: 0.6533 - val_accuracy: 0.9157\n",
            "Epoch 421/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.9762 - val_loss: 0.6088 - val_accuracy: 0.9173\n",
            "Epoch 422/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0552 - accuracy: 0.9781 - val_loss: 0.6653 - val_accuracy: 0.9160\n",
            "Epoch 423/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0618 - accuracy: 0.9775 - val_loss: 0.6647 - val_accuracy: 0.9117\n",
            "Epoch 424/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0975 - accuracy: 0.9751 - val_loss: 0.6002 - val_accuracy: 0.9131\n",
            "Epoch 425/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0572 - accuracy: 0.9771 - val_loss: 0.6430 - val_accuracy: 0.9078\n",
            "Epoch 426/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0528 - accuracy: 0.9789 - val_loss: 0.6599 - val_accuracy: 0.9142\n",
            "Epoch 427/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0608 - accuracy: 0.9760 - val_loss: 0.5890 - val_accuracy: 0.9157\n",
            "Epoch 428/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0536 - accuracy: 0.9792 - val_loss: 0.6507 - val_accuracy: 0.9113\n",
            "Epoch 429/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9781 - val_loss: 0.6253 - val_accuracy: 0.9160\n",
            "Epoch 430/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0574 - accuracy: 0.9781 - val_loss: 0.6177 - val_accuracy: 0.9127\n",
            "Epoch 431/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0526 - accuracy: 0.9795 - val_loss: 0.6757 - val_accuracy: 0.9146\n",
            "Epoch 432/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0536 - accuracy: 0.9794 - val_loss: 0.6170 - val_accuracy: 0.9171\n",
            "Epoch 433/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0524 - accuracy: 0.9791 - val_loss: 0.5950 - val_accuracy: 0.9164\n",
            "Epoch 434/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9773 - val_loss: 0.6473 - val_accuracy: 0.9184\n",
            "Epoch 435/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0656 - accuracy: 0.9755 - val_loss: 0.6089 - val_accuracy: 0.9132\n",
            "Epoch 436/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9772 - val_loss: 0.6451 - val_accuracy: 0.9117\n",
            "Epoch 437/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0551 - accuracy: 0.9789 - val_loss: 0.6469 - val_accuracy: 0.9135\n",
            "Epoch 438/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0599 - accuracy: 0.9757 - val_loss: 0.6275 - val_accuracy: 0.9116\n",
            "Epoch 439/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0561 - accuracy: 0.9778 - val_loss: 0.5930 - val_accuracy: 0.9141\n",
            "Epoch 440/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0555 - accuracy: 0.9781 - val_loss: 0.6131 - val_accuracy: 0.9156\n",
            "Epoch 441/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0513 - accuracy: 0.9792 - val_loss: 0.6054 - val_accuracy: 0.9134\n",
            "Epoch 442/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0529 - accuracy: 0.9797 - val_loss: 0.6348 - val_accuracy: 0.9105\n",
            "Epoch 443/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0616 - accuracy: 0.9757 - val_loss: 0.6491 - val_accuracy: 0.9135\n",
            "Epoch 444/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0580 - accuracy: 0.9791 - val_loss: 0.6272 - val_accuracy: 0.9117\n",
            "Epoch 445/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0547 - accuracy: 0.9784 - val_loss: 0.6035 - val_accuracy: 0.9163\n",
            "Epoch 446/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0606 - accuracy: 0.9770 - val_loss: 0.6540 - val_accuracy: 0.9107\n",
            "Epoch 447/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0576 - accuracy: 0.9779 - val_loss: 0.6263 - val_accuracy: 0.9162\n",
            "Epoch 448/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0508 - accuracy: 0.9798 - val_loss: 0.6465 - val_accuracy: 0.9131\n",
            "Epoch 449/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0540 - accuracy: 0.9795 - val_loss: 0.5940 - val_accuracy: 0.9137\n",
            "Epoch 450/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0532 - accuracy: 0.9789 - val_loss: 0.6327 - val_accuracy: 0.9117\n",
            "Epoch 451/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9798 - val_loss: 0.6484 - val_accuracy: 0.9132\n",
            "Epoch 452/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0591 - accuracy: 0.9780 - val_loss: 0.6287 - val_accuracy: 0.9164\n",
            "Epoch 453/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 0.6352 - val_accuracy: 0.9124\n",
            "Epoch 454/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0573 - accuracy: 0.9782 - val_loss: 0.6542 - val_accuracy: 0.9152\n",
            "Epoch 455/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0585 - accuracy: 0.9779 - val_loss: 0.6624 - val_accuracy: 0.9145\n",
            "Epoch 456/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9787 - val_loss: 0.6876 - val_accuracy: 0.9149\n",
            "Epoch 457/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0630 - accuracy: 0.9763 - val_loss: 0.6318 - val_accuracy: 0.9117\n",
            "Epoch 458/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9795 - val_loss: 0.6589 - val_accuracy: 0.9169\n",
            "Epoch 459/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.9792 - val_loss: 0.6807 - val_accuracy: 0.9145\n",
            "Epoch 460/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9793 - val_loss: 0.6197 - val_accuracy: 0.9153\n",
            "Epoch 461/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9792 - val_loss: 0.6608 - val_accuracy: 0.9149\n",
            "Epoch 462/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0523 - accuracy: 0.9804 - val_loss: 0.6871 - val_accuracy: 0.9144\n",
            "Epoch 463/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0585 - accuracy: 0.9775 - val_loss: 0.6286 - val_accuracy: 0.9166\n",
            "Epoch 464/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0492 - accuracy: 0.9805 - val_loss: 0.6568 - val_accuracy: 0.9146\n",
            "Epoch 465/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0537 - accuracy: 0.9792 - val_loss: 0.6348 - val_accuracy: 0.9106\n",
            "Epoch 466/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0593 - accuracy: 0.9773 - val_loss: 0.6169 - val_accuracy: 0.9138\n",
            "Epoch 467/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.6309 - val_accuracy: 0.9156\n",
            "Epoch 468/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0511 - accuracy: 0.9805 - val_loss: 0.6046 - val_accuracy: 0.9114\n",
            "Epoch 469/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0545 - accuracy: 0.9790 - val_loss: 0.6734 - val_accuracy: 0.9100\n",
            "Epoch 470/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.6347 - val_accuracy: 0.9124\n",
            "Epoch 471/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0511 - accuracy: 0.9813 - val_loss: 0.6146 - val_accuracy: 0.9162\n",
            "Epoch 472/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0516 - accuracy: 0.9796 - val_loss: 0.6616 - val_accuracy: 0.9142\n",
            "Epoch 473/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9791 - val_loss: 0.6141 - val_accuracy: 0.9107\n",
            "Epoch 474/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9796 - val_loss: 0.6491 - val_accuracy: 0.9163\n",
            "Epoch 475/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0589 - accuracy: 0.9765 - val_loss: 0.6163 - val_accuracy: 0.9153\n",
            "Epoch 476/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0501 - accuracy: 0.9806 - val_loss: 0.6755 - val_accuracy: 0.9125\n",
            "Epoch 477/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.9799 - val_loss: 0.7364 - val_accuracy: 0.9113\n",
            "Epoch 478/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9796 - val_loss: 0.6291 - val_accuracy: 0.9121\n",
            "Epoch 479/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0563 - accuracy: 0.9788 - val_loss: 0.6273 - val_accuracy: 0.9095\n",
            "Epoch 480/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0492 - accuracy: 0.9810 - val_loss: 0.6429 - val_accuracy: 0.9125\n",
            "Epoch 481/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0564 - accuracy: 0.9783 - val_loss: 0.6403 - val_accuracy: 0.9137\n",
            "Epoch 482/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0504 - accuracy: 0.9804 - val_loss: 0.6530 - val_accuracy: 0.9153\n",
            "Epoch 483/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0524 - accuracy: 0.9803 - val_loss: 0.6621 - val_accuracy: 0.9148\n",
            "Epoch 484/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0533 - accuracy: 0.9795 - val_loss: 0.6578 - val_accuracy: 0.9163\n",
            "Epoch 485/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0518 - accuracy: 0.9809 - val_loss: 0.6705 - val_accuracy: 0.9142\n",
            "Epoch 486/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9826 - val_loss: 0.7011 - val_accuracy: 0.9149\n",
            "Epoch 487/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0532 - accuracy: 0.9804 - val_loss: 0.6270 - val_accuracy: 0.9128\n",
            "Epoch 488/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.9781 - val_loss: 0.6252 - val_accuracy: 0.9152\n",
            "Epoch 489/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9785 - val_loss: 0.6584 - val_accuracy: 0.9138\n",
            "Epoch 490/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0518 - accuracy: 0.9806 - val_loss: 0.6598 - val_accuracy: 0.9139\n",
            "Epoch 491/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0458 - accuracy: 0.9825 - val_loss: 0.7318 - val_accuracy: 0.9095\n",
            "Epoch 492/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0579 - accuracy: 0.9790 - val_loss: 0.6637 - val_accuracy: 0.9164\n",
            "Epoch 493/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9802 - val_loss: 0.6239 - val_accuracy: 0.9142\n",
            "Epoch 494/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0504 - accuracy: 0.9814 - val_loss: 0.6836 - val_accuracy: 0.9142\n",
            "Epoch 495/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.6568 - val_accuracy: 0.9187\n",
            "Epoch 496/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0561 - accuracy: 0.9781 - val_loss: 0.6667 - val_accuracy: 0.9145\n",
            "Epoch 497/500\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9805 - val_loss: 0.6685 - val_accuracy: 0.9105\n",
            "Epoch 498/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0479 - accuracy: 0.9813 - val_loss: 0.6469 - val_accuracy: 0.9157\n",
            "Epoch 499/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.6939 - val_accuracy: 0.9145\n",
            "Epoch 500/500\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 0.0574 - accuracy: 0.9788 - val_loss: 0.6405 - val_accuracy: 0.9142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55e315ac90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgG_OvFaRy-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e36583c-8786-41a4-ce2a-8f023b58de54"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180/180 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.9151\n",
            "Accuracy 0.9151069521903992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3euXS38oRzDV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEF8ts_NuElq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sWq_Pk8jzZk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbsf8uil-7e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvnOx5-Yl-9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLWDkgdzl_B2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9fwpNA9OnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}